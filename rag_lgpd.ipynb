{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model = \"llama3.2:3b\",\n",
    "    temperature = 0,\n",
    "    base_url='http://localhost:11434'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploração de Histórico e Rastreabilidade de Consultas usando LLMs\n",
    "\n",
    "## Objetivo\n",
    "Neste notebook, exploraremos os impactos do uso de histórico e rastreabilidade em consultas realizadas por meio de um modelo de linguagem grande (LLM). Utilizaremos metadados associados às interações para fornecer contexto e rastreabilidade, além de metadados gerados pelo próprio modelo para análise.\n",
    "\n",
    "## Modelo Utilizado\n",
    "Usaremos o modelo **Llama3.2:3B** como base, acessado via **Ollama**, uma ferramenta que facilita a integração e execução de modelos LLM localmente.\n",
    "\n",
    "## Metodologia\n",
    "1. **Histórico de Consultas**: Manteremos um log estruturado de todas as interações realizadas com o modelo.\n",
    "2. **Rastreabilidade via Metadados**: Adicionaremos informações contextuais como usuário, data, e propósito da consulta, permitindo uma análise detalhada e rastreamento das interações.\n",
    "3. **Metadados Gerados pelo Modelo**: Exploraremos como os metadados criados pelo modelo podem complementar o processo de rastreabilidade e análise.\n",
    "\n",
    "\n",
    "## Resultado Esperado\n",
    "- Análise do impacto da rastreabilidade nas consultas.\n",
    "- Organização do histórico para facilitar a auditoria e reprodutibilidade.\n",
    "- Identificação de padrões nos metadados gerados pelo modelo.\n",
    "\n",
    "## Ferramentas e Recursos\n",
    "- **Modelo**: Llama3.2:3B.\n",
    "- **Framework**: Ollama.\n",
    "- **Linguagem**: Python.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etapa 1: Pergunta Inicial ao LLM\n",
    "\n",
    "Nesta etapa, faremos uma consulta direta ao modelo de linguagem (LLM) sem fornecer informações adicionais ou contextos baseados em documentos. O objetivo é avaliar a capacidade do modelo de responder à pergunta com base em seu treinamento e conhecimento prévio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Olá!\n",
      "\n",
      "A Lei Geral de Proteção de Dados (LGPD) é uma lei brasileira que regula a proteção de dados pessoais e a sua utilização por parte de entidades públicas.\n",
      "\n",
      "O capítulo específico da LGPD que trata do tratamento de dados pessoais pelo poder público é o Capítulo VIII, que é composto pelos artigos 43 a 55.\n",
      "\n",
      "Aqui estão alguns pontos importantes relacionados ao tratamento de dados pessoais pelo poder público, conforme estabelecido na LGPD:\n",
      "\n",
      "*   Art. 43: O Poder Público deve garantir a proteção dos dados pessoais e a sua utilização apenas para fins previstos em lei.\n",
      "*   Art. 44: A coleta, armazenamento e tratamento de dados pessoais pelo Poder Público devem ser realizados por meio de instrumentos legais ou regulamentares que garantam a proteção dos dados.\n",
      "*   Art. 45: O Poder Público deve informar os cidadãos sobre as razões da coleta, armazenamento e tratamento de seus dados pessoais.\n",
      "*   Art. 46: A coleta, armazenamento e tratamento de dados pessoais pelo Poder Público devem ser realizados por meio de instrumentos legais ou regulamentares que garantam a proteção dos dados.\n",
      "\n",
      "Esses artigos estabelecem as regras básicas para o tratamento de dados pessoais pelo poder público, garantindo a proteção dos dados e a transparência nas práticas de coleta e utilização de informações pessoais.\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke(\"Qual capitulo da lgpd trata do tratamento de dados pessoais pelo poder publico?\")\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Correção e Análise\n",
    "O modelo não forneceu a resposta correta para a pergunta. De acordo com a Lei Geral de Proteção de Dados (LGPD), o capítulo que trata do tratamento de dados pessoais pelo poder público é o **Capítulo IV**, abrangendo os artigos que detalham as bases legais e os princípios aplicáveis ao tratamento de dados pelo Poder Público.\n",
    "\n",
    "Agora, para melhorar o contexto e a precisão da resposta, iremos consumir o conteúdo do **PDF da LGPD** e enviá-lo como parte do contexto para a próxima consulta ao modelo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "from pytesseract import image_to_string\n",
    "\n",
    "def extract_text_with_ocr(pdf_path):\n",
    "    extracted_text = []\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "\n",
    "            if page.extract_text():\n",
    "                extracted_text.append(page.extract_text())\n",
    "            else:\n",
    "                page_image = page.to_image(resolution=300)\n",
    "                image = page_image.original  \n",
    "                text = image_to_string(image)\n",
    "                extracted_text.append(text)\n",
    "    return extracted_text\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivo\n",
    "O objetivo desta etapa é extrair o texto completo do **PDF da LGPD** para que possamos usá-lo como contexto na próxima consulta ao modelo. \n",
    "\n",
    "## Método Utilizado\n",
    "1. **PDFPlumber**: Usado para extrair texto diretamente de páginas do PDF.\n",
    "2. **OCR (Reconhecimento Óptico de Caracteres)**: Caso o texto de uma página não seja extraído diretamente (por exemplo, devido a imagens), aplicamos o OCR usando o `pytesseract`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = \"data/lgpd.pdf\"\n",
    "text = extract_text_with_ocr(pdf_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Integração com LangChain, FAISS e Modelo Ollama\n",
    "\n",
    "## Objetivo\n",
    "Este código implementa uma pipeline de **Retrieval-Augmented Generation (RAG)**, utilizando **LangChain**, **FAISS** e o modelo **Ollama**. O objetivo é fornecer respostas contextuais baseadas em documentos previamente indexados.\n",
    "\n",
    "## **1. LangChain**\n",
    "O LangChain é uma biblioteca projetada para facilitar a integração de modelos de linguagem com ferramentas externas, como bases de dados, vetores de busca e fluxos de trabalho complexos.\n",
    "\n",
    "### Componentes Utilizados:\n",
    "- **`langchain.schema.Document`**: Representa um documento estruturado com conteúdo textual que pode ser utilizado em pipelines de recuperação de informações.\n",
    "- **`langchain.schema.HumanMessage`**: Utilizado para encapsular mensagens enviadas por um usuário humano para interação com modelos de linguagem.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. HuggingFaceEmbeddings**\n",
    "Esta tecnologia é utilizada para converter textos em representações vetoriais (embeddings) que podem ser usadas para buscas semânticas e recuperação de informações.\n",
    "\n",
    "- **Modelo Utilizado**: `all-MiniLM-L6-v2`\n",
    "  - Este modelo, baseado no framework HuggingFace, é otimizado para gerar embeddings de alta qualidade em tarefas de similaridade semântica e recuperação de informações.\n",
    "- **Função**: Permitir a indexação de textos em um espaço vetorial, tornando possível a busca por documentos semelhantes com base em consultas.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. FAISS (Facebook AI Similarity Search)**\n",
    "FAISS é uma biblioteca altamente otimizada para busca de similaridade em grandes coleções de dados vetoriais.\n",
    "\n",
    "### Por que FAISS?\n",
    "- **Eficiência**: Projetado para realizar buscas rápidas e escaláveis em dados vetoriais.\n",
    "- **Integração**: Fácil integração com embeddings gerados pelo HuggingFace ou outros frameworks.\n",
    "- **Função no Código**:\n",
    "  - Armazena os embeddings dos documentos.\n",
    "  - Permite recuperar os documentos mais relevantes com base na similaridade entre o texto da consulta e os documentos indexados.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.schema import Document, HumanMessage\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "\n",
    "\n",
    "def create_documents(texts):\n",
    "    if isinstance(texts, list):\n",
    "        documents = [Document(page_content=text) for text in texts]\n",
    "    else:\n",
    "        documents = [Document(page_content=texts)]\n",
    "    return documents\n",
    "\n",
    "def create_faiss_vectorstore(documents):\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "    vectorstore = FAISS.from_documents(documents, embeddings)\n",
    "    return vectorstore\n",
    "\n",
    "def generate_response_with_ollama(vectorstore, query):\n",
    "    retriever = vectorstore.as_retriever()\n",
    "    retrieved_docs = retriever.invoke(query)\n",
    "    context = \"\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "    \n",
    "    print(\"Contexto Recuperado:\")\n",
    "    print(context[:200])\n",
    "    \n",
    "    prompt = f\"Contexto: {context}\\n\\nPergunta: {query}\\nResposta:\"\n",
    "    response = llm.invoke([HumanMessage(content=prompt)])\n",
    "    return response.content.strip()\n",
    "\n",
    "def rag_pipeline_with_ollama(texts, query):\n",
    "    documents = create_documents(texts)\n",
    "    vectorstore = create_faiss_vectorstore(documents)\n",
    "    response = generate_response_with_ollama(vectorstore, query)\n",
    "    return response\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contexto Recuperado:\n",
      "DIARIO OFICIAL DA UNIAO\n",
      "\n",
      "Publicado em: 15/08/2018 | Edic&o: 157 | Segao: 1 | Pagina: 59\n",
      "Orgao: Atos do Poder Legislativo\n",
      "\n",
      "LEI NO 13.709, DE 14 DE AGOSTO DE 2018\n",
      "\n",
      "Disp6e sobre a protegao de dados pesso\n",
      "\n",
      "Resposta Gerada: O capítulo que trata do tratamento de dados pessoais pelo poder público é o Capítulo IV, intitulado \"Tratamento de Dados Pessoais por Poder Público\".\n"
     ]
    }
   ],
   "source": [
    "query = \"Qual capítulo da LGPD trata do tratamento de dados pessoais pelo poder público?\"\n",
    "response = rag_pipeline_with_ollama(text, query)\n",
    "\n",
    "# Exibir resposta gerada\n",
    "print(\"\\nResposta Gerada:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise da Resposta\n",
    "Após incluir o texto da **Lei Geral de Proteção de Dados (LGPD)** como contexto, o modelo conseguiu gerar uma resposta **correta e precisa**. O **Capítulo IV** é, de fato, o capítulo da LGPD que trata do tratamento de dados pessoais pelo poder público.\n",
    "\n",
    "---\n",
    "\n",
    "## Observação\n",
    "Este resultado demonstra que o fornecimento de um **contexto relevante** (neste caso, o texto da lei) melhora significativamente a precisão das respostas geradas pelo modelo. Inicialmente, sem o contexto, a resposta era incorreta.\n",
    "\n",
    "---\n",
    "\n",
    "## Benefício do Contexto Adicional\n",
    "A inclusão do texto da LGPD como contexto foi essencial para:\n",
    "1. **Proporcionar ao modelo informações diretas e relevantes**.\n",
    "2. **Garantir que a resposta fosse fundamentada em uma fonte confiável**.\n",
    "\n",
    "## Proximos passos será o de usar multiplos documentos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pdfplumber\n",
    "from pytesseract import image_to_string\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.schema import Document\n",
    "from langchain_ollama import ChatOllama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_with_ocr(pdf_path):\n",
    "\n",
    "    extracted_text = []\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            if page.extract_text():\n",
    "                extracted_text.append(page.extract_text())\n",
    "            else:\n",
    "                page_image = page.to_image(resolution=300)\n",
    "                image = page_image.original\n",
    "                text = image_to_string(image, lang=\"por\")\n",
    "                extracted_text.append(text)\n",
    "    return \"\\n\".join(extracted_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf_documents(pdf_paths):\n",
    "\n",
    "    all_documents = []\n",
    "    for path in pdf_paths:\n",
    "        print(f\"Carregando: {path}\")\n",
    "        try:\n",
    "            # Extract and consolidate text from the PDF\n",
    "            text = extract_text_with_ocr(path)\n",
    "            filename = os.path.basename(path)\n",
    "            document = Document(\n",
    "                page_content=text,\n",
    "                metadata={\"source\": filename}  # Metadata includes the file name\n",
    "            )\n",
    "            all_documents.append(document)\n",
    "            print(f\"Documento consolidado para {filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao carregar {path}: {e}\")\n",
    "\n",
    "    if not all_documents:\n",
    "        raise ValueError(\"Nenhum documento foi carregado. Verifique os caminhos dos PDFs.\")\n",
    "    \n",
    "    print(f\"Total de documentos carregados: {len(all_documents)}\")\n",
    "    return all_documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vectorstore(documents):\n",
    "\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    vectorstore = FAISS.from_documents(documents, embeddings)\n",
    "    return vectorstore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(query, vectorstore):\n",
    "\n",
    "    docs = vectorstore.similarity_search(query, k=5)\n",
    "    context = \"\\n\\n\".join([\n",
    "        f\"Source: {doc.metadata.get('source', 'Unknown')}\\nContent: {doc.page_content}\" for doc in docs\n",
    "    ])\n",
    "    \n",
    "\n",
    "    prompt = f\"Contexto: {context}\\n\\nPergunta: {query}\\nResposta:\"\n",
    "    response = llm.invoke([prompt])\n",
    "    \n",
    "    output = {\n",
    "        \"question\": query,\n",
    "        \"context\": context[:500],\n",
    "        \"response\": response.content.strip(),\n",
    "        \"sources\": [doc.metadata.get(\"source\", \"Unknown\") for doc in docs]\n",
    "    }\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_vectorstore(pdf_paths):\n",
    "\n",
    "    documents = load_pdf_documents(pdf_paths)\n",
    "    vectorstore = create_vectorstore(documents)\n",
    "    print(\"Vectorstore criado com sucesso.\")\n",
    "    return vectorstore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question(query, vectorstore):\n",
    "\n",
    "    response = generate_response(query, vectorstore)\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando: data/lgpd.pdf\n",
      "Documento consolidado para lgpd.pdf\n",
      "Carregando: data/codigo_civil.pdf\n",
      "Documento consolidado para codigo_civil.pdf\n",
      "Total de documentos carregados: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_94430/2212122749.py:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorstore criado com sucesso.\n"
     ]
    }
   ],
   "source": [
    "pdf_files = [\"data/lgpd.pdf\", \"data/codigo_civil.pdf\"]\n",
    "vectorstore = prepare_vectorstore(pdf_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pergunta: definicao lei geral de protecao de dados\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Resposta Gerada:\n",
      "Lei Geral de Proteção de Dados (LGPD)\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Contexto: Source: lgpd.pdf\n",
      "Content: DIÁRIO OFICIAL DA UNIÃO\n",
      "\n",
      "Publicado em: 15/08/2018 | Edição: 157 | Seção: 1 | Página: 59\n",
      "Órgão: Atos do Poder Legislativo\n",
      "\n",
      "LEI NO 13.709, DE 14 DE AGOSTO DE 2018\n",
      "\n",
      "Dispõe sobre a proteção de dados pessoais e altera a Lei nº\n",
      "12.965, de 23 de abril de 2014 (Marco Civil da Internet).\n",
      "\n",
      "OPRESIDENTEDAREPÚBLICA\n",
      "Faço saber que o Congresso Nacional decreta e eu sanciono a seguinte Lei:\n",
      "CAPÍTULO |\n",
      "DISPOSIÇÕES PRELIMINARES\n",
      "\n",
      "Art. 1º Esta Lei dispõe sobre o tratamento de dados pessoai\n",
      "\n",
      "Fontes:\n",
      "- codigo_civil.pdf\n",
      "- lgpd.pdf\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query1 = \"definicao lei geral de protecao de dados\"\n",
    "response1 = ask_question(query1, vectorstore)\n",
    "print(\"Pergunta:\", response1[\"question\"])\n",
    "\n",
    "print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "print(\"\\nResposta Gerada:\")\n",
    "print(response1[\"response\"])\n",
    "\n",
    "print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "print(\"Contexto:\", response1[\"context\"])\n",
    "print(\"\\nFontes:\")\n",
    "for source in set(response1[\"sources\"]):\n",
    "    print(\"-\", source)\n",
    "\n",
    "print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pergunta: capitulo das perdas e danos?\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Resposta Gerada:\n",
      "Capítulo VI.\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Contexto: Source: lgpd.pdf\n",
      "Content: DIÁRIO OFICIAL DA UNIÃO\n",
      "\n",
      "Publicado em: 15/08/2018 | Edição: 157 | Seção: 1 | Página: 59\n",
      "Órgão: Atos do Poder Legislativo\n",
      "\n",
      "LEI NO 13.709, DE 14 DE AGOSTO DE 2018\n",
      "\n",
      "Dispõe sobre a proteção de dados pessoais e altera a Lei nº\n",
      "12.965, de 23 de abril de 2014 (Marco Civil da Internet).\n",
      "\n",
      "OPRESIDENTEDAREPÚBLICA\n",
      "Faço saber que o Congresso Nacional decreta e eu sanciono a seguinte Lei:\n",
      "CAPÍTULO |\n",
      "DISPOSIÇÕES PRELIMINARES\n",
      "\n",
      "Art. 1º Esta Lei dispõe sobre o tratamento de dados pessoai\n",
      "\n",
      "Fontes:\n",
      "- codigo_civil.pdf\n",
      "- lgpd.pdf\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query2 = \"capitulo das perdas e danos?\"\n",
    "response2 = ask_question(query2, vectorstore)\n",
    "print(\"Pergunta:\", response2[\"question\"])\n",
    "\n",
    "print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "print(\"\\nResposta Gerada:\")\n",
    "print(response2[\"response\"])\n",
    "\n",
    "print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "print(\"Contexto:\", response2[\"context\"])\n",
    "print(\"\\nFontes:\")\n",
    "for source in set(response2[\"sources\"]):\n",
    "    print(\"-\", source)\n",
    "\n",
    "print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observação Inicial\n",
    "Recuperamos as fontes utilizadas pelo sistema para responder a perguntas. No entanto, notamos que elas não estão **bem distribuídas**. \n",
    "\n",
    "### Problema Identificado\n",
    "Ao fazer perguntas específicas sobre a **LGPD**, o sistema consultou fontes não relacionadas, como o **Código Civil** (`codigo_civil.pdf`). Isso indica que:\n",
    "1. O sistema de recuperação de documentos está incluindo fontes irrelevantes.\n",
    "2. As respostas geradas podem ser influenciadas por documentos que não são pertinentes ao tema consultado.\n",
    "\n",
    "---\n",
    "\n",
    "## Solução Proposta: Uso de Chunks\n",
    "Para melhorar a precisão e relevância das fontes utilizadas, vamos implementar o **uso de chunks**. Essa abordagem permite dividir documentos em blocos menores, facilitando a recuperação de partes mais específicas e relevantes.\n",
    "\n",
    "### Benefícios do Uso de Chunks\n",
    "1. **Maior Precisão**: Reduz a probabilidade de incluir documentos irrelevantes ao restringir a busca a trechos específicos.\n",
    "2. **Contexto Focado**: Aumenta a relevância do contexto recuperado para responder a perguntas específicas.\n",
    "3. **Melhor Gerenciamento de Fontes**: Garante que as respostas sejam fundamentadas em documentos diretamente relacionados ao tema.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text_into_chunks(text, chunk_size=1000, overlap=200):\n",
    "\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(text):\n",
    "        end = start + chunk_size\n",
    "        chunks.append(text[start:end])\n",
    "        start = end - overlap if end - overlap > start else end\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf_documents_with_chunks(pdf_paths, chunk_size=1000, overlap=200):\n",
    "\n",
    "    all_documents = []\n",
    "    for path in pdf_paths:\n",
    "        print(f\"Carregando: {path}\")\n",
    "        try:\n",
    "            text = extract_text_with_ocr(path)\n",
    "            filename = os.path.basename(path)\n",
    "            chunks = split_text_into_chunks(text, chunk_size, overlap)\n",
    "            for i, chunk in enumerate(chunks):\n",
    "                document = Document(\n",
    "                    page_content=chunk,\n",
    "                    metadata={\"source\": filename, \"chunk_index\": i}\n",
    "                )\n",
    "                all_documents.append(document)\n",
    "            print(f\"{len(chunks)} chunks criados para {filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao carregar {path}: {e}\")\n",
    "\n",
    "    if not all_documents:\n",
    "        raise ValueError(\"Nenhum documento foi carregado. Verifique os caminhos dos PDFs.\")\n",
    "    \n",
    "    print(f\"Total de chunks carregados: {len(all_documents)}\")\n",
    "    return all_documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_vectorstore_with_chunks(pdf_paths, chunk_size=1000, overlap=200):\n",
    "\n",
    "    documents = load_pdf_documents_with_chunks(pdf_paths, chunk_size, overlap)\n",
    "    vectorstore = create_vectorstore(documents)\n",
    "    print(\"Vectorstore criado com chunks.\")\n",
    "    return vectorstore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando: data/lgpd.pdf\n",
      "72 chunks criados para lgpd.pdf\n",
      "Carregando: data/codigo_civil.pdf\n",
      "1666 chunks criados para codigo_civil.pdf\n",
      "Total de chunks carregados: 1738\n",
      "Vectorstore criado com chunks.\n"
     ]
    }
   ],
   "source": [
    "# Carregar documentos, dividir em chunks e criar vetorstore\n",
    "pdf_files = [\"data/lgpd.pdf\", \"data/codigo_civil.pdf\"]\n",
    "vectorstore_with_chunks = prepare_vectorstore_with_chunks(pdf_files, chunk_size=1000, overlap=200)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reexecução de Perguntas Após a Divisão em Chunks\n",
    "\n",
    "## Objetivo\n",
    "Após implementar a divisão dos documentos em chunks, vamos refazer as mesmas perguntas para avaliar se:\n",
    "1. A recuperação de contexto está mais precisa.\n",
    "2. Fontes irrelevantes, como o **Código Civil**, não estão mais sendo consultadas em perguntas sobre a **LGPD**.\n",
    "3. As respostas geradas pelo modelo são mais relevantes e contextualizadas.\n",
    "\n",
    "---\n",
    "\n",
    "## Metodologia\n",
    "1. **Pipeline Atualizada**: Utilizar a pipeline com o vetorstore criado a partir dos documentos divididos em chunks.\n",
    "2. **Análise das Respostas**:\n",
    "   - Verificar se os chunks recuperados pertencem às fontes esperadas.\n",
    "   - Avaliar se as respostas geradas estão em conformidade com a pergunta.\n",
    "3. **Registro das Fontes**:\n",
    "   - Analisar as fontes consultadas para garantir que apenas documentos relevantes foram utilizados.\n",
    "\n",
    "---\n",
    "\n",
    "## Resultados Esperados\n",
    "1. Respostas mais precisas e contextualizadas, diretamente relacionadas aos documentos corretos.\n",
    "2. Consultas à **LGPD** limitadas aos chunks de `lgpd.pdf`, eliminando interferências de fontes irrelevantes como `codigo_civil.pdf`.\n",
    "3. Melhor rastreabilidade das fontes devido aos metadados incluídos em cada chunk.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pergunta: definicao lei geral de protecao de dados\n",
      "\n",
      "Resposta Gerada:\n",
      "A Lei Geral de Proteção de Dados Pessoais (LGPD) define a proteção de dados pessoais como um direito fundamental que visa garantir a privacidade e a segurança dos indivíduos em relação à coleta, armazenamento e tratamento de suas informações pessoais. A LGPD estabelece regras e princípios para proteger os dados pessoais, incluindo a necessidade de consentimento informado, a transparência e a responsabilidade nos tratamentos de dados, além da proteção contra violações e danos causados ao titular dos dados.\n",
      "\n",
      "A LGPD também estabelece direitos do titular dos dados, como o direito de acesso, correção e eliminação de seus dados, bem como o direito de portabilidade e revogação do consentimento. Além disso, a lei estabelece responsabilidades para os controladores e operadores de tratamento de dados, incluindo a necessidade de implementar medidas de segurança adequadas e informar os titulares dos dados sobre as práticas de tratamento.\n",
      "\n",
      "Em resumo, a LGPD define a proteção de dados pessoais como um direito fundamental que visa garantir a privacidade e a segurança dos indivíduos em relação à coleta, armazenamento e tratamento de suas informações pessoais.\n",
      "\n",
      "Fontes:\n",
      "- lgpd.pdf\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Pergunta: capitulo das perdas e danos?\n",
      "\n",
      "Resposta Gerada:\n",
      "O Capítulo III das Perdas e Danos.\n",
      "\n",
      "Fontes:\n",
      "- codigo_civil.pdf\n"
     ]
    }
   ],
   "source": [
    "# Fazer uma pergunta\n",
    "query1 = \"definicao lei geral de protecao de dados\"\n",
    "response1 = ask_question(query1, vectorstore_with_chunks)\n",
    "\n",
    "print(\"Pergunta:\", response1[\"question\"])\n",
    "print(\"\\nResposta Gerada:\")\n",
    "print(response1[\"response\"])\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nFontes:\")\n",
    "for source in set(response1[\"sources\"]):\n",
    "    print(\"-\", source)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query2 = \"capitulo das perdas e danos?\"\n",
    "response2 = ask_question(query2, vectorstore_with_chunks)\n",
    "\n",
    "print(\"Pergunta:\", response2[\"question\"])\n",
    "print(\"\\nResposta Gerada:\")\n",
    "print(response2[\"response\"])\n",
    "\n",
    "print(\"\\nFontes:\")\n",
    "for source in set(response2[\"sources\"]):\n",
    "    print(\"-\", source)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultados Após a Implementação dos Chunks\n",
    "\n",
    "## Observação\n",
    "Após dividir os documentos em **chunks**, refizemos as perguntas utilizando a nova pipeline. Com essa abordagem, conseguimos:\n",
    "\n",
    "1. **Recuperar as Fontes Corretamente**:\n",
    "   - As perguntas sobre a **LGPD** consultaram apenas os chunks relevantes de `lgpd.pdf`.\n",
    "   - Fontes irrelevantes, como o `codigo_civil.pdf`, não foram mais incluídas no contexto.\n",
    "\n",
    "2. **Respostas Mais Assertivas**:\n",
    "   - As respostas geradas pelo modelo foram mais precisas e alinhadas às perguntas feitas.\n",
    "   - A relevância e o contexto melhoraram significativamente devido ao uso de chunks menores e bem definidos.\n",
    "\n",
    "---\n",
    "\n",
    "## Benefícios Identificados\n",
    "1. **Melhor Foco no Contexto**:\n",
    "   - O sistema agora prioriza trechos específicos dos documentos, reduzindo a interferência de fontes não relacionadas.\n",
    "2. **Aumento na Precisão**:\n",
    "   - Respostas mais confiáveis e fundamentadas, com base em documentos diretamente relevantes ao tema da pergunta.\n",
    "3. **Rastreabilidade**:\n",
    "   - Cada resposta pode ser associada aos chunks e documentos específicos usados para gerar o contexto.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementação de Histórico na Interação com o Modelo\n",
    "\n",
    "## Objetivo\n",
    "Adicionar um histórico de conversas para que o modelo possa basear suas respostas em interações anteriores, fornecendo um contexto mais rico e um feedback mais assertivo.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_history_with_previous(history):\n",
    "    \"\"\"\n",
    "    Inclua todo o histórico, destacando explicitamente a interação mais recente.\n",
    "    \"\"\"\n",
    "    if not history:\n",
    "        return \"Histórico vazio.\"\n",
    "\n",
    "    # Última interação (pergunta e resposta anterior)\n",
    "    last_interaction = f\"Pergunta Anterior: {history[-1][0]}\\nResposta Anterior: {history[-1][1]}\"\n",
    "    \n",
    "    # Outras interações (exceto a última)\n",
    "    previous_interactions = \"\\n\".join([\n",
    "        f\"Pergunta: {q}\\nResposta: {r}\" for q, r in history[:-1]\n",
    "    ])\n",
    "    \n",
    "    # Combinar tudo\n",
    "    return f\"{previous_interactions}\\n\\n{last_interaction}\" if previous_interactions else last_interaction\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_prompt_with_history(query, context, history):\n",
    "\n",
    "    # Incluir o histórico completo\n",
    "    full_history = summarize_history_with_previous(history)\n",
    "    \n",
    "    # Destacar a última interação diretamente no contexto\n",
    "    if history:\n",
    "        last_question, last_answer = history[-1]\n",
    "        last_interaction_context = f\"Baseando-se na última interação:\\nPergunta: {last_question}\\nResposta: {last_answer}\\n\"\n",
    "    else:\n",
    "        last_interaction_context = \"\"\n",
    "\n",
    "    # Construir o prompt\n",
    "    prompt = f\"\"\"\n",
    "    Você é um assistente jurídico especializado no Código Civil brasileiro.\n",
    "\n",
    "    Última Interação:\n",
    "    {last_interaction_context}\n",
    "\n",
    "    Histórico de Conversa:\n",
    "    {full_history}\n",
    "\n",
    "    Trechos relevantes dos documentos:\n",
    "    {context}\n",
    "\n",
    "    Nova Pergunta:\n",
    "    {query}\n",
    "\n",
    "    Resposta:\n",
    "    \"\"\"\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_response_with_history(query, vectorstore, history):\n",
    "\n",
    "    docs = vectorstore.similarity_search(query, k=5)\n",
    "    \n",
    "    context = \"\\n\\n\".join([\n",
    "        f\"Fonte: {doc.metadata.get('source', 'Desconhecido')}\\nTrecho: {doc.page_content[:300]}\" for doc in docs\n",
    "    ])\n",
    "    \n",
    "    \n",
    "    prompt = format_prompt_with_history(query, context, history)\n",
    "    \n",
    "    response = llm.invoke([prompt])\n",
    "    \n",
    "    history.append((query, response.content.strip()))\n",
    "    \n",
    "    output = {\n",
    "        \"question\": query,\n",
    "        \"response\": response.content.strip(),\n",
    "        \"sources\": [doc.metadata.get(\"source\", \"Desconhecido\") for doc in docs],\n",
    "        \"context_used\": context  \n",
    "    }\n",
    "    return output\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ask_question_with_history(query, vectorstore, history):\n",
    "\n",
    "    return generate_response_with_history(query, vectorstore, history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resposta Gerada:\n",
      "Olá! Estou aqui para ajudar.\n",
      "\n",
      "O Livro II do Código Civil brasileiro é dividido em várias partes, incluindo:\n",
      "\n",
      "**Capítulo I: Do Testamento**\n",
      "\n",
      "* Seção 1: Disposições gerais sobre o testamento\n",
      "* Seção 2: Do testamento de vontade\n",
      "* Seção 3: Do testamento de necessidade\n",
      "\n",
      "**Capítulo II: Da Dote**\n",
      "\n",
      "* Seção 1: Disposições gerais sobre a dote\n",
      "* Seção 2: Da dote em espécie\n",
      "* Seção 3: Da dote em dinheiro\n",
      "\n",
      "**Capítulo III: Da Adoção**\n",
      "\n",
      "* Seção 1: Disposições gerais sobre a adoção\n",
      "* Seção 2: Do regime de direitos da adotiva\n",
      "* Seção 3: Da adoção especial\n",
      "\n",
      "Essas são as principais partes do Livro II do Código Civil brasileiro. Se tiver alguma dúvida específica, sinta-se à vontade para perguntar!\n",
      "Fonte: codigo_civil.pdf\n",
      "Trecho:  que são objeto do Livro II da Parte Especial deste\n",
      "Código.\n",
      "Art. 45. Começa a existência legal das pessoas jurídicas de direito privado com\n",
      "a inscrição do ato constitutivo no respectivo registro, precedida, quando necessário,\n",
      "de autorização ou aprovação do Poder Executivo, averbando-se no registro t\n",
      "\n",
      "Fonte: codigo_civil.pdf\n",
      "Trecho: enciais, tais como o de eticidade, de socialidade e de operabilidade.\n",
      "542 Código Civil Brasileiro\n",
      "d) Aproveitamento dos trabalhos de reforma da Lei Civil, nas duas meritórias\n",
      "tentativas feitas, anteriormente, por ilustres jurisconsultos, primeiro por Hahneman\n",
      "Guimarães, Orozimbo Nonato e Philadelpho\n",
      "\n",
      "Fonte: codigo_civil.pdf\n",
      "Trecho: gou o capítulo sobre\n",
      "adoção especial, inscrito no Código de 1967” (Código Civile e Sistema Civilistico:\n",
      "II nucleo codicistico ed i suoi satelliti, in Rivista de Diritto Civile, Ano XXXIX, n.\n",
      "4, 1993, p. 403-413, cits. p. 406 e 410).\n",
      "Tem alcance amplo, portanto, a tendência redutora da importância do\n",
      "\n",
      "Fonte: codigo_civil.pdf\n",
      "Trecho:  a teses abstratas, visando a elaborar, sob a denominação de “Código\n",
      "Civil”, um “Código de Direito Privado”, o qual, se possível fora, seria de discutível\n",
      "utilidade ou conveniência.\n",
      "Na realidade, o que se realizou, no âmbito do Código Civil, foi a unidade do Di-\n",
      "reito das Obrigações, de conformidade\n",
      "\n",
      "Fonte: codigo_civil.pdf\n",
      "Trecho: 170 – É resgatável a enfiteuse instituída anteriormente à vigência do Código Civil.\n",
      "165 – A venda realizada diretamente pelo mandante ao mandatário não é atingida pela\n",
      "nulidade do art. 1.135, II, do Código Civil.\n",
      "163 – Salvo contra a Fazenda Pública, sendo a obrigação ilíquida, contam-se os juros\n",
      "mo\n",
      "\n",
      "Fontes:\n",
      "- codigo_civil.pdf\n"
     ]
    }
   ],
   "source": [
    "conversation_history = []\n",
    "\n",
    "response1 = ask_question_with_history(\n",
    "    \"Quais são os capítulos e seções do Livro II do Código Civil?\", \n",
    "    vectorstore_with_chunks, \n",
    "    conversation_history\n",
    ")\n",
    "\n",
    "print(\"\\nResposta Gerada:\")\n",
    "print(response1[\"response\"])\n",
    "print(response1[\"context_used\"])\n",
    "print(\"\\nFontes:\")\n",
    "for source in set(response1[\"sources\"]):\n",
    "    print(\"-\", source)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise da Resposta\n",
    "A resposta gerada está **incorreta**. Os capítulos e seções apresentados não correspondem ao conteúdo real do **Livro II do Código Civil brasileiro**.\n",
    "\n",
    "---\n",
    "\n",
    "## Próxima Ação: Passar a Definição Correta no Próximo Input\n",
    "Para corrigir o erro, vamos:\n",
    "1. **Inserir a definição correta** dos capítulos e seções do Livro II como parte do próximo input.\n",
    "2. **Atualizar o histórico** para que o modelo possa melhorar sua resposta com base no contexto correto.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resposta Gerada:\n",
      "Olá! Estou aqui para ajudar.\n",
      "\n",
      "Você está correto em dizer que os capítulos do Livro II do Código Civil são:\n",
      "\n",
      "**Livro II - Dos Bens**\n",
      "\n",
      "**Título Único - Das Diferentes Classes de Bens**\n",
      "\n",
      "**Capítulo I - Dos Bens Considerados em Si Mesmos**\n",
      "\n",
      "* Seção I - Dos Bens Imóveis\n",
      "* Seção II - Dos Bens Móveis\n",
      "* Seção III - Dos Bens Fungíveis e Consumíveis\n",
      "* Seção IV - Dos Bens Divisíveis\n",
      "* Seção V - Dos Bens Singulares e Coletivos\n",
      "\n",
      "**Capítulo II - Dos Bens Reciprocamente Considerados**\n",
      "\n",
      "* Capítulo III - Dos Bens Públicos\n",
      "\n",
      "Fontes:\n",
      "- codigo_civil.pdf\n"
     ]
    }
   ],
   "source": [
    "response2 = ask_question_with_history(\n",
    "    '''Os capítulos do Livro II do Código Civil são Livro II – Dos Bens\n",
    "Título Único – Das Diferentes Classes de Bens\n",
    "\n",
    "Capítulo I – Dos Bens Considerados em Si Mesmos\n",
    "Seção I – Dos Bens Imóveis\n",
    "Seção II – Dos Bens Móveis\n",
    "Seção III – Dos Bens Fungíveis e Consumíveis\n",
    "Seção IV – Dos Bens Divisíveis\n",
    "Seção V – Dos Bens Singulares e Coletivos\n",
    "Capítulo II – Dos Bens Reciprocamente Considerados\n",
    "Capítulo III – Dos Bens Públicos''', \n",
    "    vectorstore_with_chunks, \n",
    "    conversation_history\n",
    ")\n",
    "\n",
    "print(\"\\nResposta Gerada:\")\n",
    "print(response2[\"response\"])\n",
    "print(\"\\nFontes:\")\n",
    "for source in set(response2[\"sources\"]):\n",
    "    print(\"-\", source)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reexecução da Pergunta com Feedback Fornecido\n",
    "\n",
    "## Contexto\n",
    "Após identificar que a resposta gerada anteriormente estava **incorreta**, fornecemos ao modelo o feedback necessário com a definição correta dos capítulos e seções do **Livro II do Código Civil**.\n",
    "\n",
    "---\n",
    "\n",
    "## Próxima Ação\n",
    "Agora, faremos a mesma pergunta novamente para verificar se o modelo:\n",
    "1. **Incorporou o feedback fornecido**.\n",
    "2. **Gera uma resposta correta** baseada no novo contexto.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Próximos Passos\n",
    "1. **Executar a pergunta novamente**.\n",
    "2. **Analisar a resposta gerada** para validar se ela corresponde ao contexto fornecido.\n",
    "3. Documentar os resultados e, se necessário, continuar ajustando o modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resposta Gerada:\n",
      "Olá! Estou aqui para ajudar.\n",
      "\n",
      "O Livro II do Código Civil é dividido em dois capítulos:\n",
      "\n",
      "**Capítulo I - Dos Bens Considerados em Si Mesmos**\n",
      "\n",
      "* Seção I - Dos Bens Imóveis\n",
      "* Seção II - Dos Bens Móveis\n",
      "* Seção III - Dos Bens Fungíveis e Consumíveis\n",
      "* Seção IV - Dos Bens Divisíveis\n",
      "* Seção V - Dos Bens Singulares e Coletivos\n",
      "\n",
      "**Capítulo II - Dos Bens Reciprocamente Considerados**\n",
      "\n",
      "* Capítulo III - Dos Bens Públicos\n",
      "\n",
      "Fontes:\n",
      "- codigo_civil.pdf\n"
     ]
    }
   ],
   "source": [
    "response3 = ask_question_with_history(\n",
    "    \"Quais são os capítulos e seções do Livro II do Código Civil?\", \n",
    "    vectorstore_with_chunks, \n",
    "    conversation_history\n",
    ")\n",
    "\n",
    "print(\"\\nResposta Gerada:\")\n",
    "print(response3[\"response\"])\n",
    "print(\"\\nFontes:\")\n",
    "for source in set(response3[\"sources\"]):\n",
    "    print(\"-\", source)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uso do Histórico e Introdução ao Cross-Encoder\n",
    "\n",
    "## 1. Histórico Utilizado com Sucesso\n",
    "O uso do histórico na interação demonstrou ser eficaz para melhorar a precisão das respostas. Após fornecer o feedback necessário ao modelo e reutilizar o histórico, conseguimos obter a **resposta correta** para a pergunta:\n",
    "\n",
    "**Pergunta**: *\"Quais são os capítulos e seções do Livro II do Código Civil?\"*\n",
    "\n",
    "**Resposta Gerada**:  \n",
    "- **Livro II – Dos Bens**  \n",
    "- **Título Único – Das Diferentes Classes de Bens**\n",
    "\n",
    "### Benefícios do Histórico\n",
    "1. **Aprendizado Contínuo**: O modelo ajustou suas respostas com base no feedback e nas interações anteriores.\n",
    "2. **Melhoria na Precisão**: As respostas passaram a refletir melhor o contexto fornecido.\n",
    "3. **Contexto Rico**: O histórico permitiu ao modelo considerar informações adicionais e construir respostas mais completas.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Hipótese: Uso de Cross-Encoder para Melhorar a Rastreabilidade\n",
    "Podemos explorar o uso de um **cross-encoder** para refinar ainda mais o sistema. \n",
    "\n",
    "### O que é um Cross-Encoder?\n",
    "O cross-encoder é uma técnica de aprendizado profundo que:\n",
    "1. **Atribui pontuações de similaridade** diretamente entre a consulta e os trechos de texto recuperados.\n",
    "2. **Reavalia o contexto de maneira mais precisa** ao considerar todas as interações entre o texto e a consulta.\n",
    "\n",
    "### Benefícios Esperados do Cross-Encoder\n",
    "1. **Melhor Rastreabilidade**:\n",
    "   - O cross-encoder pode identificar com maior precisão os trechos mais relevantes, permitindo que o modelo utilize apenas os dados mais confiáveis.\n",
    "2. **Contexto Otimizado**:\n",
    "   - Refinando a seleção de trechos, o modelo terá um contexto mais relevante para gerar respostas.\n",
    "3. **Respostas Mais Precisas**:\n",
    "   - O uso de pontuações de similaridade permite ao sistema priorizar trechos que respondam diretamente à consulta, minimizando a interferência de informações secundárias.\n",
    "\n",
    "### Próximos Passos\n",
    "1. **Implementar o Cross-Encoder**:\n",
    "   - Integrar o modelo de cross-encoder para reavaliar os trechos recuperados antes de passá-los ao modelo.\n",
    "2. **Validar Hipótese**:\n",
    "   - Testar o impacto do cross-encoder na rastreabilidade e precisão das respostas.\n",
    "3. **Comparação com Resultados Anteriores**:\n",
    "   - Analisar as melhorias introduzidas pelo cross-encoder em relação ao uso do histórico sozinho.\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusão\n",
    "O uso do histórico melhorou significativamente as respostas do modelo, mas a introdução de um cross-encoder pode ser uma solução adicional para refinar ainda mais a rastreabilidade e precisão do sistema.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "\n",
    "def rerank_documents_with_crossencoder(query: str, docs: List, model_name: str = \"cross-encoder/ms-marco-MiniLM-L-6-v2\") -> List:\n",
    "    \"\"\"\n",
    "    Reorganiza os documentos usando um modelo CrossEncoder com base na relevância para a consulta.\n",
    "    \"\"\"\n",
    "    if not docs:\n",
    "        return []\n",
    "\n",
    "    # Inicializar o modelo CrossEncoder\n",
    "    cross_encoder = CrossEncoder(model_name)\n",
    "\n",
    "    # Criar pares de (query, document) para o modelo\n",
    "    query_doc_pairs = [(query, doc.page_content) for doc in docs]\n",
    "\n",
    "    # Obter scores de relevância\n",
    "    scores = cross_encoder.predict(query_doc_pairs)\n",
    "\n",
    "    # Ordenar os documentos pelo score em ordem decrescente\n",
    "    sorted_docs = [doc for _, doc in sorted(zip(scores, docs), key=lambda x: x[0], reverse=True)]\n",
    "\n",
    "    return sorted_docs\n",
    "\n",
    "\n",
    "\n",
    "def generate_response_with_rerank(query: str, vectorstore, history: List) -> dict:\n",
    "    \"\"\"\n",
    "    Gera uma resposta utilizando re-ranking dos documentos mais relevantes para a consulta.\n",
    "    \"\"\"\n",
    "    # Buscar mais documentos relevantes no Vectorstore\n",
    "    initial_docs = vectorstore.similarity_search(query, k=10)  # Aumentado para considerar mais documentos\n",
    "\n",
    "    if not initial_docs:\n",
    "        return {\n",
    "            \"question\": query,\n",
    "            \"response\": \"Nenhum documento relevante encontrado para a consulta.\",\n",
    "            \"sources\": [],\n",
    "            \"context_used\": \"\"\n",
    "        }\n",
    "\n",
    "    # Aplicar re-ranking nos documentos retornados\n",
    "    reranked_docs = rerank_documents_with_crossencoder(query, initial_docs)\n",
    "\n",
    "    # Selecionar os top 5 documentos após o re-ranking\n",
    "  \n",
    "\n",
    "    # Construir o contexto a partir dos documentos selecionados\n",
    "    context = \"\\n\\n\".join([\n",
    "        f\"Fonte: {doc.metadata.get('source', 'Desconhecido')}\\nTrecho: {doc.page_content}\" for doc in reranked_docs\n",
    "    ])\n",
    "\n",
    "    # Gerar o prompt com o histórico e contexto\n",
    "    #prompt \n",
    "\n",
    "    prompt = format_prompt_with_history(query, context, history)\n",
    "    # Obter a resposta do modelo LLM\n",
    "    response = llm.invoke([prompt])\n",
    "\n",
    "    # Adicionar a interação ao histórico\n",
    "    history.append((query, response.content.strip()))\n",
    "\n",
    "    # Formatar a saída\n",
    "    output = {\n",
    "        \"question\": query,\n",
    "        \"response\": response.content.strip(),\n",
    "        \"sources\": [doc.metadata.get(\"source\", \"Desconhecido\") for doc in reranked_docs],\n",
    "        \"context_used\": context\n",
    "    }\n",
    "    return output\n",
    "\n",
    "def ask_question_with_rerank(query: str, vectorstore, history: List) -> dict:\n",
    "    \"\"\"\n",
    "    Wrapper para gerar respostas com re-ranking utilizando o CrossEncoder.\n",
    "    \"\"\"\n",
    "    return generate_response_with_rerank(query, vectorstore, history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resposta Gerada:\n",
      "Infelizmente, não há uma resposta explícita na texto fornecido. No entanto, posso tentar ajudá-lo a identificar os capítulos e seções do Livro II do Código Civil brasileiro.\n",
      "\n",
      "O Livro II do Código Civil brasileiro é intitulado \"Das Pessoas\". Ele é dividido em 7 títulos:\n",
      "\n",
      "1. Título I: Da Personalidade\n",
      "2. Título II: Da Família\n",
      "3. Título III: Das Sucessões\n",
      "4. Título IV: Do Testamento\n",
      "5. Título V: Dos Poderes\n",
      "6. Título VI: Da Fidelidade e da Confiança\n",
      "7. Título VII: Da Responsabilidade\n",
      "\n",
      "Cada título é dividido em seções, artigos e parágrafos.\n",
      "\n",
      "Se você puder fornecer mais contexto ou informações sobre o Livro II do Código Civil brasileiro, posso tentar ajudá-lo a identificar os capítulos e seções específicas que está procurando.\n",
      "Fonte: codigo_civil.pdf\n",
      "Trecho:  que são objeto do Livro II da Parte Especial deste\n",
      "Código.\n",
      "Art. 45. Começa a existência legal das pessoas jurídicas de direito privado com\n",
      "a inscrição do ato constitutivo no respectivo registro, precedida, quando necessário,\n",
      "de autorização ou aprovação do Poder Executivo, averbando-se no registro todas as\n",
      "alterações por que passar o ato constitutivo.\n",
      "Parágrafo único. Decai em três anos o direito de anular a constituição das pes-\n",
      "soas jurídicas de direito privado, por defeito do ato respectivo, contado o prazo da\n",
      "publicação de sua inscrição no registro.\n",
      "Art. 46. O registro declarará:\n",
      "I – a denominação, os fins, a sede, o tempo de duração e o fundo social,\n",
      "quando houver;\n",
      "56 Lei no 10.825/2003.\n",
      "Código Civil Brasileiro 149\n",
      "II – o nome e a individualização dos fundadores ou instituidores, e dos dire-\n",
      "tores;\n",
      "III – o modo por que se administra e representa, ativa e passivamente, judicial\n",
      "e extrajudicialmente;\n",
      "IV – se o ato constitutivo é reformável no tocante à administração, e de que\n",
      "modo;\n",
      "\n",
      "\n",
      "Fonte: codigo_civil.pdf\n",
      "Trecho:  “valiosas contribuições”, “tais como os An-\n",
      "Código Civil Brasileiro 533\n",
      "teprojetos de Código de Obrigações, de 1941 e de 1965”, “e o Anteprojeto de Código\n",
      "Civil, de 1963, de autoria do Prof. Orlando Gomes” (In Código Civil, 1o vol., Parte\n",
      "Geral – Pub. da Subsecretaria de Edições Técnicas do Senado Federal, Bras., 1975).\n",
      "5 – O relato do Professor Miguel Reale esclarece, ainda, e pertinentemente, que,\n",
      "“abandonada a linha de reforma que vinha sendo seguida”, ou seja, a de elaboração\n",
      "“de dois códigos distintos” – o Código Civil e o Código de Obrigações -, idéia que –\n",
      "acentua -” não logrou boa acolhida”, prevaleceu a orientação de feitura de um texto\n",
      "fundamental. Concisamente assevera que predominou, entre as diretrizes essenciais,\n",
      "a “compreensão do Código Civil como lei básica, mas não global, do Direito Priva-\n",
      "do, conservando-se em seu âmbito, por conseguinte, o Direito das Obrigações, sem\n",
      "distinção entre obrigações civis e mercantis”.\n",
      "6 – Veio ao Congresso Nacional, portanto, já unifica\n",
      "\n",
      "Fonte: codigo_civil.pdf\n",
      "Trecho:  que exercer permanentemente suas funções; o do\n",
      "militar, onde servir, e, sendo da Marinha ou da Aeronáutica, a sede do comando a\n",
      "que se encontrar imediatamente subordinado; o do marítimo, onde o navio estiver\n",
      "matriculado; e o do preso, o lugar em que cumprir a sentença.\n",
      "Art. 77. O agente diplomático do Brasil, que, citado no estrangeiro, alegar extrater-\n",
      "ritorialidade sem designar onde tem, no país, o seu domicílio, poderá ser demandado\n",
      "no Distrito Federal ou no último ponto do território brasileiro onde o teve.\n",
      "Art. 78. Nos contratos escritos, poderão os contratantes especificar domicílio onde\n",
      "se exercitem e cumpram os direitos e obrigações deles resultantes.\n",
      "Livro ii\n",
      "Dos Bens\n",
      "TÍTuLo úNiCo\n",
      "Das Diferentes Classes de Bens\n",
      "CAPÍTuLo i\n",
      "Dos Bens Considerados em Si Mesmos\n",
      "SEção i\n",
      "Dos Bens Imóveis\n",
      "Art. 79. São bens imóveis o solo e tudo quanto se lhe incorporar natural ou arti-\n",
      "ficialmente.\n",
      "Art. 80. Consideram-se imóveis para os efeitos legais:\n",
      "154 Código Civil Brasileiro\n",
      "I – os direitos reai\n",
      "\n",
      "Fonte: codigo_civil.pdf\n",
      "Trecho: enciais, tais como o de eticidade, de socialidade e de operabilidade.\n",
      "542 Código Civil Brasileiro\n",
      "d) Aproveitamento dos trabalhos de reforma da Lei Civil, nas duas meritórias\n",
      "tentativas feitas, anteriormente, por ilustres jurisconsultos, primeiro por Hahneman\n",
      "Guimarães, Orozimbo Nonato e Philadelpho de Azevedo, com o anteprojeto do “Có-\n",
      "digo das Obrigações”; e, depois, por Orlando Gomes e Caio Mario da Silva Pereira,\n",
      "com a proposta de elaboração separada de um Código Civil e de um Código das\n",
      "Obrigações, contando com a colaboração, neste caso, de Silvio Marcondes, Theóphilo\n",
      "de Azevedo Santos e Nehemias Gueiros.\n",
      "e) Firmar a orientação de somente inserir no Código matéria já consolidada ou\n",
      "com relevante grau de experiência crítica, transferindo-se para a legislação especial\n",
      "aditiva o regramento de questões ainda em processo de estudo, ou que, por sua natureza\n",
      "complexa, envolvem problemas e soluções que extrapolam do Código Civil.\n",
      "f) Dar nova estrutura ao Código, mantendo-se a Parte Geral \n",
      "\n",
      "Fonte: codigo_civil.pdf\n",
      "Trecho: BrE o\n",
      "ProJETo DE CÓDiGo CiviL\n",
      "Josaphat Marinho – Relator-Geral\n",
      "Sumário\n",
      "Breve histórico – Providência frustrada – Observações preliminares – Direito sem\n",
      "unidade – Codificação – Declínio da codificação. Leis especiais – O problema no\n",
      "Brasil – Outras razões ponderáveis – Prudência e flexibilidade – Novos subsídios.\n",
      "Breve histórico\n",
      "1 – A iniciativa, propriamente dita, da elaboração de novo Código Civil coube ao\n",
      "governo Jânio Quadros, cujo Ministro da Justiça, Oscar Pedroso d’Horta, confiou o\n",
      "preparo de anteprojeto, em 1961, ao Professor Orlando Gomes. Pouco após o começo\n",
      "do trabalho do jurista baiano, sobreveio a renúncia do presidente da República.\n",
      "2 – No governo João Goulart, o Ministro da Justiça João Mangabeira, em outubro\n",
      "de 1962, retomou o estudo da matéria, renovando a confiança no professor Orlando\n",
      "Gomes, que apresentou o Anteprojeto em março de 1963. Submetido a uma Comissão\n",
      "Revisora, que participaram, com o autor, o Ministro Orozimbo Nonato e o professor\n",
      "Caio Mário da Silva Perei\n",
      "\n",
      "Fonte: codigo_civil.pdf\n",
      "Trecho: .........204\n",
      "Capítulo IV – Da Doação\n",
      "Seção I – Disposições Gerais ......................................................................204\n",
      "Seção II – Da Revogação da Doação ..........................................................206\n",
      "Capítulo V – Da Locação de Coisas ...............................................................207\n",
      "Capítulo VI – Do Empréstimo\n",
      "Seção I – Do Comodato ...............................................................................209\n",
      "Seção II – Do Mútuo ...................................................................................209\n",
      "Capítulo VII – Da Prestação de Serviço .........................................................210\n",
      "Capítulo VIII – Da Empreitada ......................................................................212\n",
      "Capítulo IX – Do Depósito\n",
      "Seção I – Do Depósito Voluntário ...............................................................214\n",
      "Seção II – Do Depósito Necessário ...........................................................\n",
      "\n",
      "Fonte: codigo_civil.pdf\n",
      "Trecho: a reforma das es-\n",
      "truturas devesse ser cumprida através da substituição do Código Civil”, nem por isso\n",
      "confundiu “o problema da reforma com o problema da codificação”. E explicou: “A\n",
      "reforma pode ser gradualmente realizada mediante a introdução no sistema jurídico\n",
      "de leis que modificam institutos codificados ou que exprimem a filosofia da mudança,\n",
      "remediando a crise de legitimidade”. Anota que uma visão das leis especiais editadas\n",
      "Código Civil Brasileiro 537\n",
      "no Brasil, a partir de 1930, permite o mapeamento das partes necrosadas do código,\n",
      "já substituídas por outras”, dotadas de funcionalidade, e indica o Código de Águas,\n",
      "o Código de Minas, o Código Florestal, o Código de Menores, e à frente deles, pela\n",
      "idade e pela importância, a Consolidação das Leis do Trabalho”. Realçando as “tensões\n",
      "e contradições da civilização industrial dos dias correntes”, entende que “a substitui-\n",
      "ção global de um Código Civil é atualmente um anacronismo”. Reforça a tese para\n",
      "considerar decisão dessa natureza\n",
      "\n",
      "Fonte: codigo_civil.pdf\n",
      "Trecho: essor Orlando\n",
      "Gomes, que apresentou o Anteprojeto em março de 1963. Submetido a uma Comissão\n",
      "Revisora, que participaram, com o autor, o Ministro Orozimbo Nonato e o professor\n",
      "Caio Mário da Silva Pereira, e sujeito a debate em instituições de cultura, o Anteprojeto\n",
      "foi entregue, solenemente, em 28 de setembro de 1963, ao Ministro da Justiça Milton\n",
      "Campos, já no governo Castello Branco.\n",
      "É o que, resumidamente, informa o professor Orlando Gomes no livro “A Reforma\n",
      "do Código Civil (Publs. da Univ. da Bahia, 1965).\n",
      "3 – Em maio de 1969, foi constituída “Comissão Revisora e Elaboradora do\n",
      "Código Civil”, composta dos professores Miguel Reale, na qualidade de Supervisor,\n",
      "José Carlos Moreira Alves, Agostinho de Arruda Alvim, Sylvio Marcondes, Ebert\n",
      "Chamoun, Clovis do Couto e Silva e Torquato Castro, de cujos estudos “resultou\n",
      "novo Anteprojeto, publicado em 18 de junho de 1974”.\n",
      "Eis o que noticia a exposição de motivos do Ministro da Justiça Armando Falcão,\n",
      "de 1975, dirigida ao presidente Ernesto\n",
      "\n",
      "Fonte: codigo_civil.pdf\n",
      "Trecho: as rodoviária e ferroviária\n",
      "federais;\n",
      "XXIII – seguridade social;\n",
      "XXIV – diretrizes e bases da educação nacional;\n",
      "XXV – registros públicos;\n",
      "XXVI – atividades nucleares de qualquer natureza;\n",
      "XXVII – normas gerais de licitação e contratação, em todas as modalidades,\n",
      "para as administrações públicas diretas, autárquicas e fundacionais da União, Estados,\n",
      "Distrito Federal e Municípios, obedecido o disposto no art. 37, XXI, e para as empresas\n",
      "públicas e sociedades de economia mista, nos termos do art. 173, §1o, III;\n",
      "XXVIII – defesa territorial, defesa aeroespacial, defesa marítima, defesa civil\n",
      "e mobilização nacional;\n",
      "XXIX – propaganda comercial.\n",
      "Código Civil Brasileiro 31\n",
      "Parágrafo único. Lei complementar poderá autorizar os Estados a legislar sobre\n",
      "questões específicas das matérias relacionadas neste artigo.\n",
      "Art. 23. É competência comum da União, dos Estados, do Distrito Federal e dos\n",
      "Municípios:9\n",
      "I – zelar pela guarda da Constituição, das leis e das instituições democráticas\n",
      "e conservar o p\n",
      "\n",
      "Fonte: codigo_civil.pdf\n",
      "Trecho: condição, a lei poderá permitir que outras causas sejam também\n",
      "processadas e julgadas pela Justiça estadual.\n",
      "§ 4o Na hipótese do parágrafo anterior, o recurso cabível será sempre para o Tri-\n",
      "bunal Regional Federal na área de jurisdição do juiz de primeiro grau.\n",
      "§ 5o Nas hipóteses de grave violação de direitos humanos, o Procurador-Geral da\n",
      "República, com a finalidade de assegurar o cumprimento de obrigações decorrentes\n",
      "de tratados internacionais de direitos humanos dos quais o Brasil seja parte, poderá\n",
      "suscitar, perante o Superior Tribunal de Justiça, em qualquer fase do inquérito ou\n",
      "processo, incidente de deslocamento de competência para a Justiça Federal.\n",
      "50 Código Civil Brasileiro\n",
      "Art. 110. Cada Estado, bem como o Distrito Federal, constituirá uma seção judiciá-\n",
      "ria, que terá por sede a respectiva capital, e varas localizadas segundo o estabelecido\n",
      "em lei.\n",
      "Parágrafo único. Nos Territórios Federais, a jurisdição e as atribuições cometidas\n",
      "aos juízes federais caberão aos juízes da Jus\n",
      "\n",
      "Fontes:\n",
      "- codigo_civil.pdf\n"
     ]
    }
   ],
   "source": [
    "conversation_history = []\n",
    "\n",
    "response1 = ask_question_with_rerank(\n",
    "    \"Quais são os capítulos e seções do Livro II do Código Civil brasileiro?\", \n",
    "    vectorstore_with_chunks, \n",
    "    conversation_history\n",
    "    \n",
    ")\n",
    "\n",
    "print(\"\\nResposta Gerada:\")\n",
    "print(response1[\"response\"])\n",
    "print(response1[\"context_used\"])\n",
    "print(\"\\nFontes:\")\n",
    "for source in set(response1[\"sources\"]):\n",
    "    print(\"-\", source)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultados do Uso de Rerank na Recuperação de Contexto\n",
    "\n",
    "## Observação\n",
    "Com a introdução do **rerank** no pipeline. A técnica conseguiu priorizar trechos que mencionam mais diretamente a **keyword \"Livro II\"**, resultando em um contexto mais relevante para a pergunta.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Limitações Identificadas\n",
    "Apesar da melhoria no contexto recuperado, a **resposta gerada pelo modelo ainda está incorreta**. Isso pode indicar:\n",
    "1. **Interpretação Limitada do Modelo**:\n",
    "   - O modelo não está aproveitando plenamente o contexto priorizado pelo rerank.\n",
    "2. **Necessidade de Ajustes no Contexto**:\n",
    "   - O contexto, embora relevante, pode não estar detalhado o suficiente para auxiliar o modelo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resposta Gerada:\n",
      "Os capítulos do Livro II do Código Civil são:\n",
      "\n",
      "1. Capítulo I - Dos Bens Considerados em Si Mesmos\n",
      "   - Seção I - Dos Bens Imóveis\n",
      "   - Seção II - Dos Bens Móveis\n",
      "   - Seção III - Dos Bens Fungíveis e Consumíveis\n",
      "   - Seção IV - Dos Bens Divisíveis\n",
      "   - Seção V - Dos Bens Singulares e Coletivos\n",
      "\n",
      "2. Capítulo II - Dos Bens Reciprocamente Considerados\n",
      "\n",
      "3. Capítulo III - Dos Bens Públicos\n",
      "\n",
      "Fontes:\n",
      "- codigo_civil.pdf\n"
     ]
    }
   ],
   "source": [
    "response2 = ask_question_with_rerank(\n",
    "    '''Os capítulos do Livro II do Código Civil são Livro II – Dos Bens\n",
    "Título Único – Das Diferentes Classes de Bens\n",
    "\n",
    "Capítulo I – Dos Bens Considerados em Si Mesmos\n",
    "Seção I – Dos Bens Imóveis\n",
    "Seção II – Dos Bens Móveis\n",
    "Seção III – Dos Bens Fungíveis e Consumíveis\n",
    "Seção IV – Dos Bens Divisíveis\n",
    "Seção V – Dos Bens Singulares e Coletivos\n",
    "Capítulo II – Dos Bens Reciprocamente Considerados\n",
    "Capítulo III – Dos Bens Públicos''', \n",
    "    vectorstore_with_chunks, \n",
    "    conversation_history\n",
    ")\n",
    "\n",
    "print(\"\\nResposta Gerada:\")\n",
    "print(response2[\"response\"])\n",
    "print(\"\\nFontes:\")\n",
    "for source in set(response2[\"sources\"]):\n",
    "    print(\"-\", source)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resposta Gerada:\n",
      "Infelizmente não consegui encontrar as informações solicitadas.\n",
      "\n",
      "Fontes:\n",
      "- codigo_civil.pdf\n"
     ]
    }
   ],
   "source": [
    "response3 = ask_question_with_rerank(\n",
    "    \"Quais são os capítulos e seções do Livro II do Código Civil?\", \n",
    "    vectorstore_with_chunks, \n",
    "    conversation_history\n",
    ")\n",
    "\n",
    "print(\"\\nResposta Gerada:\")\n",
    "print(response3[\"response\"])\n",
    "print(\"\\nFontes:\")\n",
    "for source in set(response3[\"sources\"]):\n",
    "    print(\"-\", source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise: Histórico e Rerank\n",
    "\n",
    "## Observação Geral\n",
    "Embora tenhamos introduzido o uso do histórico e do rerank para melhorar a recuperação de contexto e a precisão das respostas, o modelo apresentou limitações em interações mais longas e iterativas. Na terceira pergunta, mesmo após o feedback fornecido, o modelo **não conseguiu encontrar a resposta correta**.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdução ao Uso de Metadados na Recuperação de Documentos\n",
    "\n",
    "## Objetivo\n",
    "Melhorar a rastreabilidade e precisão na recuperação de informações ao:\n",
    "1. **Incluir metadados** como Livro, Capítulo e Seção em cada chunk extraído dos documentos.\n",
    "2. Estruturar os chunks de forma mais granular, associando cada parte do texto aos seus respectivos metadados.\n",
    "\n",
    "---\n",
    "## Hipotese\n",
    "1. Preparar um vetorstore utilizando documentos com metadados para consultas mais precisas.\n",
    "---\n",
    "\n",
    "## Beneficio\n",
    "1. Facilitar a rastreabilidade, associando cada chunk aos metadados contextuais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def split_chunks_v2(text, chunk_size=1000, overlap=200):\n",
    "\n",
    "    # Padrões para detectar Livro, Capítulo e Seção (case-insensitive)\n",
    "    livro_pattern = re.compile(r\"(Livro\\s+[IVXLCDM\\d]+\\s*.*?)\\s*(?=\\n|$)\", re.IGNORECASE)\n",
    "    capitulo_pattern = re.compile(r\"(Capítulo\\s+[IVXLCDM\\d]+\\s*.*?)\\s*(?=\\n|$)\", re.IGNORECASE)\n",
    "    secao_pattern = re.compile(r\"(Seção\\s+[IVXLCDM\\d]+\\s*.*?)\\s*(?=\\n|$)\", re.IGNORECASE)\n",
    "\n",
    "    # Variáveis para acompanhar os metadados atuais\n",
    "    current_livro = None\n",
    "    current_capitulo = None\n",
    "    current_secao = None\n",
    "\n",
    "    # Lista de chunks e variáveis de controle\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_size = 0\n",
    "\n",
    "    def save_chunk_and_reset():\n",
    "        nonlocal current_chunk, current_size\n",
    "        if current_chunk:\n",
    "            chunks.append({\n",
    "                \"content\": \"\\n\".join(current_chunk),\n",
    "                \"metadata\": {\n",
    "                    \"livro\": current_livro,\n",
    "                    \"capítulo\": current_capitulo,\n",
    "                    \"seção\": current_secao\n",
    "                }\n",
    "            })\n",
    "            # Reiniciar mantendo o overlap\n",
    "            current_chunk = current_chunk[-overlap:]\n",
    "            current_size = sum(len(line) for line in current_chunk)\n",
    "\n",
    "    # Processar linhas do texto\n",
    "    for line in text.split(\"\\n\"):\n",
    "        # Detectar mudanças nos metadados\n",
    "        if livro_match := livro_pattern.match(line):\n",
    "            save_chunk_and_reset()\n",
    "            current_livro = livro_match.group(1)\n",
    "\n",
    "        if capitulo_match := capitulo_pattern.match(line):\n",
    "            save_chunk_and_reset()\n",
    "            current_capitulo = capitulo_match.group(1)\n",
    "\n",
    "        if secao_match := secao_pattern.match(line):\n",
    "            save_chunk_and_reset()\n",
    "            current_secao = secao_match.group(1)\n",
    "\n",
    "        # Adicionar linha ao chunk atual\n",
    "        current_chunk.append(line)\n",
    "        current_size += len(line)\n",
    "\n",
    "        # Criar chunk se atingir o tamanho definido\n",
    "        if current_size >= chunk_size:\n",
    "            save_chunk_and_reset()\n",
    "\n",
    "    # Adicionar o último chunk\n",
    "    save_chunk_and_reset()\n",
    "\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "def load_pdf_documents_v2(pdf_paths, chunk_size=1000, overlap=200):\n",
    "\n",
    "    documents = []\n",
    "    \n",
    "    for pdf_path in pdf_paths:\n",
    "        try:\n",
    "            # Abrir o PDF\n",
    "            with pdfplumber.open(pdf_path) as pdf:\n",
    "                print(f\"Processando arquivo: {pdf_path}\")\n",
    "                for page_number, page in enumerate(pdf.pages, start=1):\n",
    "                    # Extrair texto da página\n",
    "                    text = page.extract_text()\n",
    "                    \n",
    "                    if text:\n",
    "\n",
    "\n",
    "                        # Dividir o texto em chunks\n",
    "                        chunks = split_chunks_v2(text, chunk_size, overlap)\n",
    "                        \n",
    "                        if not chunks:\n",
    "                            continue\n",
    "                        \n",
    "                        # Adicionar chunks à lista de documentos\n",
    "                        for chunk in chunks:\n",
    "                            documents.append(Document(\n",
    "                                page_content=chunk[\"content\"],\n",
    "                                metadata={\n",
    "                                    \"source\": pdf_path,\n",
    "                                    \"page\": page_number,\n",
    "                                    **chunk[\"metadata\"]  # Inclui metadados como Livro, Capítulo, Seção\n",
    "                                }\n",
    "                            ))\n",
    "                    else:\n",
    "                            pass\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao processar o arquivo {pdf_path}: {e}\")\n",
    "    \n",
    "    if not documents:\n",
    "        print(\"Nenhum documento foi carregado. Verifique os arquivos PDF ou os métodos de extração.\")\n",
    "    else:\n",
    "        print(f\"Carregados {len(documents)} documentos do total de {len(pdf_paths)} arquivos PDF.\")\n",
    "\n",
    "    return documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_vectorstore_with_chunks_v2(pdf_paths, chunk_size=2000, overlap=300):\n",
    "    # Carregar documentos estruturados com resumos\n",
    "    documents = load_pdf_documents_v2(pdf_paths, chunk_size, overlap)\n",
    "\n",
    "    # Criar vetorstore\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    vectorstore = FAISS.from_documents(documents, embeddings)\n",
    "    \n",
    "    return [vectorstore, documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando arquivo: data/lgpd.pdf\n",
      "Processando arquivo: data/codigo_civil.pdf\n",
      "Carregados 4519 documentos do total de 2 arquivos PDF.\n"
     ]
    }
   ],
   "source": [
    "vectorstore_with_chunks_v, documents = prepare_vectorstore_with_chunks_v2(pdf_files, chunk_size=2000, overlap=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resposta Gerada:\n",
      "As perdas e danos são conceitos importantes na teoria jurídica, especialmente no contexto do direito civil. Aqui está uma explicação detalhada sobre o que são perdas e danos:\n",
      "\n",
      "**O que são perdas?**\n",
      "\n",
      "As perdas são os prejuízos ou consequências negativas que alguém sofre como resultado de um ato ou ação de outra pessoa. São consideradas como parte do dano causado pela outra pessoa e devem ser compensadas ao vítima.\n",
      "\n",
      "**Tipos de perdas**\n",
      "\n",
      "Existem diferentes tipos de perdas, incluindo:\n",
      "\n",
      "1. **Perda patrimonial**: é o valor do bem ou direito que foi perdido ou danificado.\n",
      "2. **Perda de oportunidade**: é o valor do que poderia ter sido ganho se a situação tivesse sido diferente.\n",
      "3. **Perda de conforto**: é o valor do conforto e da qualidade de vida que foi perdido.\n",
      "4. **Perda de reputação**: é o valor da reputação e do prestígio que foi danificado.\n",
      "\n",
      "**O que são danos?**\n",
      "\n",
      "Os danos são os prejuízos ou consequências negativas que alguém sofre como resultado de um ato ou ação de outra pessoa. São considerados como parte do dano causado pela outra pessoa e devem ser compensadas ao vítima.\n",
      "\n",
      "**Tipos de danos**\n",
      "\n",
      "Existem diferentes tipos de danos, incluindo:\n",
      "\n",
      "1. **Danos físicos**: são os prejuízos físicos sofridos pela vítima.\n",
      "2. **Danos emocionais**: são os prejuízos emocionais sofridos pela vítima.\n",
      "3. **Danos materiais**: são os prejuízos materiais sofridos pela vítima.\n",
      "\n",
      "**Como são calculados as perdas e danos?**\n",
      "\n",
      "As perdas e danos são calculados com base nos fatos do caso e nas leis aplicáveis. Em geral, é necessário demonstrar que o ato ou ação da outra pessoa causou os prejuízos e que os prejuízos foram irreversíveis.\n",
      "\n",
      "**Importância das perdas e danos**\n",
      "\n",
      "As perdas e danos são importantes porque permitem que as vítimas sejam compensadas pelo dano causado pela outra pessoa. Além disso, ajudam a estabelecer a responsabilidade do agressor e a garantir que ele seja punido por seus atos.\n",
      "\n",
      "Em resumo, as perdas e danos são conceitos importantes na teoria jurídica que permitem que as vítimas sejam compensadas pelo dano causado pela outra pessoa. É fundamental entender os tipos de perdas e danos, como são calculados e a importância delas no contexto do direito civil.\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Primeiro Contexto Utilizado:\n",
      "Livro: None\n",
      "Capítulo: CAPÍTuLo iii\n",
      "Seção: None\n",
      "Conteúdo:\n",
      " CAPÍTuLo iii\n",
      "Das Perdas e Danos\n",
      "Art. 402. Salvo as exceções expressamente previstas em lei, as perdas e danos\n",
      "devidas ao credor abrangem, além do que ele efetivamente perdeu, o que razoavel-\n",
      "mente deixou de lucrar.\n",
      "Art. 403. Ainda que a inexecução resulte de dolo do devedor, as perdas e danos só\n",
      "incluem os prejuízos efetivos e os lucros cessantes por efeito dela direto e imediato,\n",
      "sem prejuízo do disposto na lei processual.\n",
      "Art. 404. As perdas e danos, nas obrigações de pagamento em dinheiro, serão pagas\n",
      "com atualização monetária segundo índices oficiais regularmente estabelecidos, abran-\n",
      "gendo juros, custas e honorários de advogado, sem prejuízo da pena convencional.\n",
      "Parágrafo único. Provado que os juros da mora não cobrem o prejuízo, e não ha-\n",
      "vendo pena convencional, pode o juiz conceder ao credor indenização suplementar.\n",
      "Art. 405. Contam-se os juros de mora desde a citação inicial.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def ask_question_with_history_v2(question, vectorstore, conversation_history):\n",
    "\n",
    "    from langchain.chains import ConversationalRetrievalChain\n",
    "    from langchain.chains.question_answering import load_qa_chain\n",
    "    from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "\n",
    "    qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "        llm=llm,\n",
    "        retriever=vectorstore.as_retriever(),\n",
    "        return_source_documents=True  # Garante que as fontes sejam retornadas\n",
    "    )\n",
    "\n",
    "    result = qa_chain({\"question\": question, \"chat_history\": conversation_history})\n",
    "\n",
    "    conversation_history.append((question, result[\"answer\"]))\n",
    "\n",
    "    metadata_list = []\n",
    "    for doc in result[\"source_documents\"]:\n",
    "        metadata = doc.metadata\n",
    "        metadata_list.append({\n",
    "            \"livro\": metadata.get(\"livro\"),\n",
    "            \"capítulo\": metadata.get(\"capítulo\"),\n",
    "            \"seção\": metadata.get(\"seção\"),\n",
    "            \"content\": doc.page_content  \n",
    "        })\n",
    "\n",
    "    return {\n",
    "        \"response\": result[\"answer\"],\n",
    "        \"context_used\": metadata_list,\n",
    "    }\n",
    "\n",
    "\n",
    "# Exemplo de uso\n",
    "conversation_history = []\n",
    "response1 = ask_question_with_history_v2(\n",
    "    \"Perdas e danos\",\n",
    "    vectorstore_with_chunks_v,\n",
    "    conversation_history\n",
    ")\n",
    "\n",
    "# Exibir resposta e contexto\n",
    "print(\"\\nResposta Gerada:\")\n",
    "print(response1[\"response\"])\n",
    "\n",
    "print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "# print(\"Contexto utilizado:\")\n",
    "# for context in response1[\"context_used\"]:\n",
    "#     print(f\"Livro: {context['livro']}\")\n",
    "#     print(f\"Capítulo: {context['capítulo']}\")\n",
    "#     print(f\"Seção: {context['seção']}\")\n",
    "#     print(\"Conteúdo:\\n\", context[\"content\"])\n",
    "#     print(\"\\n---\\n\")\n",
    "print(\"Primeiro Contexto Utilizado:\")\n",
    "if response1[\"context_used\"]:\n",
    "    first_context = response1[\"context_used\"][0]\n",
    "    print(f\"Livro: {first_context['livro']}\")\n",
    "    print(f\"Capítulo: {first_context['capítulo']}\")\n",
    "    print(f\"Seção: {first_context['seção']}\")\n",
    "    print(\"Conteúdo:\\n\", first_context[\"content\"])\n",
    "else:\n",
    "    print(\"Nenhum contexto foi utilizado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Análise\n",
    "\n",
    "### Metadados\n",
    "- **Capítulo**: O modelo identificou corretamente o **Capítulo III – Das Perdas e Danos** como relevante.\n",
    "- **Livro e Seção**: Não foram detectados metadados específicos, mas o capítulo principal foi recuperado com sucesso.\n",
    "\n",
    "### Contexto\n",
    "- O conteúdo recuperado cita diretamente os artigos legais que tratam de perdas e danos.\n",
    "- A precisão do contexto alinhou-se à pergunta, proporcionando uma base sólida para a resposta.\n",
    "\n",
    "### Resposta\n",
    "- A resposta gerada foi bem detalhada e consistente com o contexto jurídico recuperado.\n",
    "- Incluiu explicações adicionais sobre perdas e danos, tipos e cálculo.\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusão\n",
    "O uso de metadados melhorou a **rastreamento** e a **relevância do contexto** recuperado. O modelo foi capaz de identificar o **Capítulo III – Das Perdas e Danos** e utilizá-lo para construir uma resposta clara e detalhada. Essa abordagem reforça a importância de estruturar documentos com metadados para consultas mais precisas e contextualizadas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "melhorando os metadados usando mais metadados e IA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
