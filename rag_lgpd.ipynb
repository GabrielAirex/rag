{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploração de Histórico e Rastreabilidade de Consultas usando LLMs\n",
    "\n",
    "## Objetivo\n",
    "Neste notebook, exploraremos os impactos do uso de histórico e rastreabilidade em consultas realizadas por meio de um modelo de linguagem grande (LLM). Utilizaremos metadados associados às interações para fornecer contexto e rastreabilidade, além de metadados gerados pelo próprio modelo para análise.\n",
    "\n",
    "## Modelo Utilizado\n",
    "Usaremos o modelo **Llama3.2:3B** como base, acessado via **Ollama**, uma ferramenta que facilita a integração e execução de modelos LLM localmente.\n",
    "\n",
    "## Metodologia\n",
    "1. **Histórico de Consultas**: Manteremos um log estruturado de todas as interações realizadas com o modelo.\n",
    "2. **Rastreabilidade via Metadados**: Adicionaremos informações contextuais como usuário, data, e propósito da consulta, permitindo uma análise detalhada e rastreamento das interações.\n",
    "3. **Metadados Gerados pelo Modelo**: Exploraremos como os metadados criados pelo modelo podem complementar o processo de rastreabilidade e análise.\n",
    "\n",
    "\n",
    "## Resultado Esperado\n",
    "- Análise do impacto da rastreabilidade nas consultas.\n",
    "- Organização do histórico para facilitar a auditoria e reprodutibilidade.\n",
    "- Identificação de padrões nos metadados gerados pelo modelo.\n",
    "\n",
    "## Ferramentas e Recursos\n",
    "- **Modelo**: Llama3.2:3B.\n",
    "- **Framework**: Ollama.\n",
    "- **Linguagem**: Python.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model = \"llama3.2:3b\",\n",
    "    temperature = 0,\n",
    "    base_url='http://localhost:11434'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etapa 1: Pergunta Inicial ao LLM\n",
    "\n",
    "Nesta etapa, faremos uma consulta direta ao modelo de linguagem (LLM) sem fornecer informações adicionais ou contextos baseados em documentos. O objetivo é avaliar a capacidade do modelo de responder à pergunta com base em seu treinamento e conhecimento prévio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Olá!\n",
      "\n",
      "A Lei Geral de Proteção de Dados (LGPD) é uma lei brasileira que regula a proteção de dados pessoais e a sua utilização por parte de entidades públicas.\n",
      "\n",
      "O capítulo específico da LGPD que trata do tratamento de dados pessoais pelo poder público é o Capítulo VIII, que é composto pelos artigos 43 a 55.\n",
      "\n",
      "Aqui estão alguns pontos importantes relacionados ao tratamento de dados pessoais pelo poder público, conforme estabelecido na LGPD:\n",
      "\n",
      "*   Art. 43: O Poder Público deve garantir a proteção dos dados pessoais e a sua utilização apenas para fins previstos em lei.\n",
      "*   Art. 44: A coleta, armazenamento e tratamento de dados pessoais pelo Poder Público devem ser realizados por meio de instrumentos legais ou regulamentares que garantam a proteção dos dados.\n",
      "*   Art. 45: O Poder Público deve informar os cidadãos sobre as razões da coleta, armazenamento e tratamento de seus dados pessoais.\n",
      "*   Art. 46: A coleta, armazenamento e tratamento de dados pessoais pelo Poder Público devem ser realizados por meio de instrumentos legais ou regulamentares que garantam a proteção dos dados.\n",
      "\n",
      "Esses artigos estabelecem as regras básicas para o tratamento de dados pessoais pelo poder público, garantindo a proteção dos dados e a transparência nas práticas de coleta e utilização de informações pessoais.\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke(\"Qual capitulo da lgpd trata do tratamento de dados pessoais pelo poder publico?\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Correção e Análise\n",
    "O modelo não forneceu a resposta correta para a pergunta. De acordo com a Lei Geral de Proteção de Dados (LGPD), o capítulo que trata do tratamento de dados pessoais pelo poder público é o **Capítulo IV**, abrangendo os artigos que detalham as bases legais e os princípios aplicáveis ao tratamento de dados pelo Poder Público.\n",
    "\n",
    "Agora, para melhorar o contexto e a precisão da resposta, iremos consumir o conteúdo do **PDF da LGPD** e enviá-lo como parte do contexto para a próxima consulta ao modelo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "from pytesseract import image_to_string\n",
    "\n",
    "def extract_text_with_ocr(pdf_path):\n",
    "    extracted_text = []\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "\n",
    "            if page.extract_text():\n",
    "                extracted_text.append(page.extract_text())\n",
    "            else:\n",
    "                page_image = page.to_image(resolution=300)\n",
    "                image = page_image.original  \n",
    "                text = image_to_string(image)\n",
    "                extracted_text.append(text)\n",
    "    return extracted_text\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivo\n",
    "O objetivo desta etapa é extrair o texto completo do **PDF da LGPD** para que possamos usá-lo como contexto na próxima consulta ao modelo. \n",
    "\n",
    "## Método Utilizado\n",
    "1. **PDFPlumber**: Usado para extrair texto diretamente de páginas do PDF.\n",
    "2. **OCR (Reconhecimento Óptico de Caracteres)**: Caso o texto de uma página não seja extraído diretamente (por exemplo, devido a imagens), aplicamos o OCR usando o `pytesseract`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = \"data/lgpd.pdf\"\n",
    "text = extract_text_with_ocr(pdf_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Integração com LangChain, FAISS e Modelo Ollama\n",
    "\n",
    "## Objetivo\n",
    "Este código implementa uma pipeline de **Retrieval-Augmented Generation (RAG)**, utilizando **LangChain**, **FAISS** e o modelo **Ollama**. O objetivo é fornecer respostas contextuais baseadas em documentos previamente indexados.\n",
    "\n",
    "## **1. LangChain**\n",
    "O LangChain é uma biblioteca projetada para facilitar a integração de modelos de linguagem com ferramentas externas, como bases de dados, vetores de busca e fluxos de trabalho complexos.\n",
    "\n",
    "### Componentes Utilizados:\n",
    "- **`langchain.schema.Document`**: Representa um documento estruturado com conteúdo textual que pode ser utilizado em pipelines de recuperação de informações.\n",
    "- **`langchain.schema.HumanMessage`**: Utilizado para encapsular mensagens enviadas por um usuário humano para interação com modelos de linguagem.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. HuggingFaceEmbeddings**\n",
    "Esta tecnologia é utilizada para converter textos em representações vetoriais (embeddings) que podem ser usadas para buscas semânticas e recuperação de informações.\n",
    "\n",
    "- **Modelo Utilizado**: `all-MiniLM-L6-v2`\n",
    "  - Este modelo, baseado no framework HuggingFace, é otimizado para gerar embeddings de alta qualidade em tarefas de similaridade semântica e recuperação de informações.\n",
    "- **Função**: Permitir a indexação de textos em um espaço vetorial, tornando possível a busca por documentos semelhantes com base em consultas.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. FAISS (Facebook AI Similarity Search)**\n",
    "FAISS é uma biblioteca altamente otimizada para busca de similaridade em grandes coleções de dados vetoriais.\n",
    "\n",
    "### Por que FAISS?\n",
    "- **Eficiência**: Projetado para realizar buscas rápidas e escaláveis em dados vetoriais.\n",
    "- **Integração**: Fácil integração com embeddings gerados pelo HuggingFace ou outros frameworks.\n",
    "- **Função no Código**:\n",
    "  - Armazena os embeddings dos documentos.\n",
    "  - Permite recuperar os documentos mais relevantes com base na similaridade entre o texto da consulta e os documentos indexados.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.schema import Document, HumanMessage\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "\n",
    "\n",
    "def create_documents(texts):\n",
    "    if isinstance(texts, list):\n",
    "        documents = [Document(page_content=text) for text in texts]\n",
    "    else:\n",
    "        documents = [Document(page_content=texts)]\n",
    "    return documents\n",
    "\n",
    "def create_faiss_vectorstore(documents):\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "    vectorstore = FAISS.from_documents(documents, embeddings)\n",
    "    return vectorstore\n",
    "\n",
    "def generate_response_with_ollama(vectorstore, query):\n",
    "    retriever = vectorstore.as_retriever()\n",
    "    retrieved_docs = retriever.invoke(query)\n",
    "    context = \"\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "    \n",
    "    print(\"Contexto Recuperado:\")\n",
    "    print(context[:200])\n",
    "    \n",
    "    prompt = f\"Contexto: {context}\\n\\nPergunta: {query}\\nResposta:\"\n",
    "    response = llm.invoke([HumanMessage(content=prompt)])\n",
    "    return response.content.strip()\n",
    "\n",
    "def rag_pipeline_with_ollama(texts, query):\n",
    "    documents = create_documents(texts)\n",
    "    vectorstore = create_faiss_vectorstore(documents)\n",
    "    response = generate_response_with_ollama(vectorstore, query)\n",
    "    return response\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/airex/anaconda3/envs/rag/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contexto Recuperado:\n",
      "DIARIO OFICIAL DA UNIAO\n",
      "\n",
      "Publicado em: 15/08/2018 | Edic&o: 157 | Segao: 1 | Pagina: 59\n",
      "Orgao: Atos do Poder Legislativo\n",
      "\n",
      "LEI NO 13.709, DE 14 DE AGOSTO DE 2018\n",
      "\n",
      "Disp6e sobre a protegao de dados pesso\n",
      "\n",
      "Resposta Gerada: O capítulo que trata do tratamento de dados pessoais pelo poder público é o Capítulo IV, \"Tratamento de Dados Pessoais por Poder Público\".\n"
     ]
    }
   ],
   "source": [
    "query = \"Qual capítulo da LGPD trata do tratamento de dados pessoais pelo poder público?\"\n",
    "response = rag_pipeline_with_ollama(text, query)\n",
    "\n",
    "# Exibir resposta gerada\n",
    "print(\"\\nResposta Gerada:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise da Resposta\n",
    "Após incluir o texto da **Lei Geral de Proteção de Dados (LGPD)** como contexto, o modelo conseguiu gerar uma resposta **correta e precisa**. O **Capítulo IV** é, de fato, o capítulo da LGPD que trata do tratamento de dados pessoais pelo poder público.\n",
    "\n",
    "---\n",
    "\n",
    "## Observação\n",
    "Este resultado demonstra que o fornecimento de um **contexto relevante** (neste caso, o texto da lei) melhora significativamente a precisão das respostas geradas pelo modelo. Inicialmente, sem o contexto, a resposta era incorreta.\n",
    "\n",
    "---\n",
    "\n",
    "## Benefício do Contexto Adicional\n",
    "A inclusão do texto da LGPD como contexto foi essencial para:\n",
    "1. **Proporcionar ao modelo informações diretas e relevantes**.\n",
    "2. **Garantir que a resposta fosse fundamentada em uma fonte confiável**.\n",
    "\n",
    "## Proximos passos será o de usar multiplos documentos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pdfplumber\n",
    "from pytesseract import image_to_string\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.schema import Document\n",
    "from langchain_ollama import ChatOllama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_with_ocr(pdf_path):\n",
    "\n",
    "    extracted_text = []\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            if page.extract_text():\n",
    "                extracted_text.append(page.extract_text())\n",
    "            else:\n",
    "                page_image = page.to_image(resolution=300)\n",
    "                image = page_image.original\n",
    "                text = image_to_string(image, lang=\"por\")\n",
    "                extracted_text.append(text)\n",
    "    return \"\\n\".join(extracted_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf_documents(pdf_paths):\n",
    "\n",
    "    all_documents = []\n",
    "    for path in pdf_paths:\n",
    "        print(f\"Carregando: {path}\")\n",
    "        try:\n",
    "            # Extract and consolidate text from the PDF\n",
    "            text = extract_text_with_ocr(path)\n",
    "            filename = os.path.basename(path)\n",
    "            document = Document(\n",
    "                page_content=text,\n",
    "                metadata={\"source\": filename}  # Metadata includes the file name\n",
    "            )\n",
    "            all_documents.append(document)\n",
    "            print(f\"Documento consolidado para {filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao carregar {path}: {e}\")\n",
    "\n",
    "    if not all_documents:\n",
    "        raise ValueError(\"Nenhum documento foi carregado. Verifique os caminhos dos PDFs.\")\n",
    "    \n",
    "    print(f\"Total de documentos carregados: {len(all_documents)}\")\n",
    "    return all_documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vectorstore(documents):\n",
    "\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    vectorstore = FAISS.from_documents(documents, embeddings)\n",
    "    return vectorstore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(query, vectorstore):\n",
    "\n",
    "    docs = vectorstore.similarity_search(query, k=5)\n",
    "    context = \"\\n\\n\".join([\n",
    "        f\"Source: {doc.metadata.get('source', 'Unknown')}\\nContent: {doc.page_content}\" for doc in docs\n",
    "    ])\n",
    "    \n",
    "\n",
    "    prompt = f\"Contexto: {context}\\n\\nPergunta: {query}\\nResposta:\"\n",
    "    response = llm.invoke([prompt])\n",
    "    \n",
    "    output = {\n",
    "        \"question\": query,\n",
    "        \"context\": context[:500],\n",
    "        \"response\": response.content.strip(),\n",
    "        \"sources\": [doc.metadata.get(\"source\", \"Unknown\") for doc in docs]\n",
    "    }\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_vectorstore(pdf_paths):\n",
    "\n",
    "    documents = load_pdf_documents(pdf_paths)\n",
    "    vectorstore = create_vectorstore(documents)\n",
    "    print(\"Vectorstore criado com sucesso.\")\n",
    "    return vectorstore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question(query, vectorstore):\n",
    "\n",
    "    response = generate_response(query, vectorstore)\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando: data/lgpd.pdf\n",
      "Documento consolidado para lgpd.pdf\n",
      "Carregando: data/codigo_civil.pdf\n",
      "Documento consolidado para codigo_civil.pdf\n",
      "Total de documentos carregados: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2194/2212122749.py:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorstore criado com sucesso.\n"
     ]
    }
   ],
   "source": [
    "pdf_files = [\"data/lgpd.pdf\", \"data/codigo_civil.pdf\"]\n",
    "vectorstore = prepare_vectorstore(pdf_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pergunta: definicao lei geral de protecao de dados\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Resposta Gerada:\n",
      "Lei Geral de Proteção de Dados (LGPD)\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Contexto: Source: lgpd.pdf\n",
      "Content: DIÁRIO OFICIAL DA UNIÃO\n",
      "\n",
      "Publicado em: 15/08/2018 | Edição: 157 | Seção: 1 | Página: 59\n",
      "Órgão: Atos do Poder Legislativo\n",
      "\n",
      "LEI NO 13.709, DE 14 DE AGOSTO DE 2018\n",
      "\n",
      "Dispõe sobre a proteção de dados pessoais e altera a Lei nº\n",
      "12.965, de 23 de abril de 2014 (Marco Civil da Internet).\n",
      "\n",
      "OPRESIDENTEDAREPÚBLICA\n",
      "Faço saber que o Congresso Nacional decreta e eu sanciono a seguinte Lei:\n",
      "CAPÍTULO |\n",
      "DISPOSIÇÕES PRELIMINARES\n",
      "\n",
      "Art. 1º Esta Lei dispõe sobre o tratamento de dados pessoai\n",
      "\n",
      "Fontes:\n",
      "- codigo_civil.pdf\n",
      "- lgpd.pdf\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query1 = \"definicao lei geral de protecao de dados\"\n",
    "response1 = ask_question(query1, vectorstore)\n",
    "print(\"Pergunta:\", response1[\"question\"])\n",
    "\n",
    "print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "print(\"\\nResposta Gerada:\")\n",
    "print(response1[\"response\"])\n",
    "\n",
    "print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "print(\"Contexto:\", response1[\"context\"])\n",
    "print(\"\\nFontes:\")\n",
    "for source in set(response1[\"sources\"]):\n",
    "    print(\"-\", source)\n",
    "\n",
    "print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pergunta: capitulo das perdas e danos?\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Resposta Gerada:\n",
      "Capítulo VI. Perdas e Danos.\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Contexto: Source: lgpd.pdf\n",
      "Content: DIÁRIO OFICIAL DA UNIÃO\n",
      "\n",
      "Publicado em: 15/08/2018 | Edição: 157 | Seção: 1 | Página: 59\n",
      "Órgão: Atos do Poder Legislativo\n",
      "\n",
      "LEI NO 13.709, DE 14 DE AGOSTO DE 2018\n",
      "\n",
      "Dispõe sobre a proteção de dados pessoais e altera a Lei nº\n",
      "12.965, de 23 de abril de 2014 (Marco Civil da Internet).\n",
      "\n",
      "OPRESIDENTEDAREPÚBLICA\n",
      "Faço saber que o Congresso Nacional decreta e eu sanciono a seguinte Lei:\n",
      "CAPÍTULO |\n",
      "DISPOSIÇÕES PRELIMINARES\n",
      "\n",
      "Art. 1º Esta Lei dispõe sobre o tratamento de dados pessoai\n",
      "\n",
      "Fontes:\n",
      "- codigo_civil.pdf\n",
      "- lgpd.pdf\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query2 = \"capitulo das perdas e danos?\"\n",
    "response2 = ask_question(query2, vectorstore)\n",
    "print(\"Pergunta:\", response2[\"question\"])\n",
    "\n",
    "print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "print(\"\\nResposta Gerada:\")\n",
    "print(response2[\"response\"])\n",
    "\n",
    "print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "print(\"Contexto:\", response2[\"context\"])\n",
    "print(\"\\nFontes:\")\n",
    "for source in set(response2[\"sources\"]):\n",
    "    print(\"-\", source)\n",
    "\n",
    "print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observação Inicial\n",
    "Recuperamos as fontes utilizadas pelo sistema para responder a perguntas. No entanto, notamos que elas não estão **bem distribuídas**. \n",
    "\n",
    "### Problema Identificado\n",
    "Ao fazer perguntas específicas sobre a **LGPD**, o sistema consultou fontes não relacionadas, como o **Código Civil** (`codigo_civil.pdf`). Isso indica que:\n",
    "1. O sistema de recuperação de documentos está incluindo fontes irrelevantes.\n",
    "2. As respostas geradas podem ser influenciadas por documentos que não são pertinentes ao tema consultado.\n",
    "\n",
    "---\n",
    "\n",
    "## Solução Proposta: Uso de Chunks\n",
    "Para melhorar a precisão e relevância das fontes utilizadas, vamos implementar o **uso de chunks**. Essa abordagem permite dividir documentos em blocos menores, facilitando a recuperação de partes mais específicas e relevantes.\n",
    "\n",
    "### Benefícios do Uso de Chunks\n",
    "1. **Maior Precisão**: Reduz a probabilidade de incluir documentos irrelevantes ao restringir a busca a trechos específicos.\n",
    "2. **Contexto Focado**: Aumenta a relevância do contexto recuperado para responder a perguntas específicas.\n",
    "3. **Melhor Gerenciamento de Fontes**: Garante que as respostas sejam fundamentadas em documentos diretamente relacionados ao tema.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text_into_chunks(text, chunk_size=1000, overlap=200):\n",
    "\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(text):\n",
    "        end = start + chunk_size\n",
    "        chunks.append(text[start:end])\n",
    "        start = end - overlap if end - overlap > start else end\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf_documents_with_chunks(pdf_paths, chunk_size=1000, overlap=200):\n",
    "\n",
    "    all_documents = []\n",
    "    for path in pdf_paths:\n",
    "        print(f\"Carregando: {path}\")\n",
    "        try:\n",
    "            text = extract_text_with_ocr(path)\n",
    "            filename = os.path.basename(path)\n",
    "            chunks = split_text_into_chunks(text, chunk_size, overlap)\n",
    "            for i, chunk in enumerate(chunks):\n",
    "                document = Document(\n",
    "                    page_content=chunk,\n",
    "                    metadata={\"source\": filename, \"chunk_index\": i}\n",
    "                )\n",
    "                all_documents.append(document)\n",
    "            print(f\"{len(chunks)} chunks criados para {filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao carregar {path}: {e}\")\n",
    "\n",
    "    if not all_documents:\n",
    "        raise ValueError(\"Nenhum documento foi carregado. Verifique os caminhos dos PDFs.\")\n",
    "    \n",
    "    print(f\"Total de chunks carregados: {len(all_documents)}\")\n",
    "    return all_documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_vectorstore_with_chunks(pdf_paths, chunk_size=1000, overlap=200):\n",
    "\n",
    "    documents = load_pdf_documents_with_chunks(pdf_paths, chunk_size, overlap)\n",
    "    vectorstore = create_vectorstore(documents)\n",
    "    print(\"Vectorstore criado com chunks.\")\n",
    "    return vectorstore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando: data/lgpd.pdf\n",
      "72 chunks criados para lgpd.pdf\n",
      "Carregando: data/codigo_civil.pdf\n",
      "1666 chunks criados para codigo_civil.pdf\n",
      "Total de chunks carregados: 1738\n",
      "Vectorstore criado com chunks.\n"
     ]
    }
   ],
   "source": [
    "# Carregar documentos, dividir em chunks e criar vetorstore\n",
    "pdf_files = [\"data/lgpd.pdf\", \"data/codigo_civil.pdf\"]\n",
    "vectorstore_with_chunks = prepare_vectorstore_with_chunks(pdf_files, chunk_size=1000, overlap=200)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reexecução de Perguntas Após a Divisão em Chunks\n",
    "\n",
    "## Objetivo\n",
    "Após implementar a divisão dos documentos em chunks, vamos refazer as mesmas perguntas para avaliar se:\n",
    "1. A recuperação de contexto está mais precisa.\n",
    "2. Fontes irrelevantes, como o **Código Civil**, não estão mais sendo consultadas em perguntas sobre a **LGPD**.\n",
    "3. As respostas geradas pelo modelo são mais relevantes e contextualizadas.\n",
    "\n",
    "---\n",
    "\n",
    "## Metodologia\n",
    "1. **Pipeline Atualizada**: Utilizar a pipeline com o vetorstore criado a partir dos documentos divididos em chunks.\n",
    "2. **Análise das Respostas**:\n",
    "   - Verificar se os chunks recuperados pertencem às fontes esperadas.\n",
    "   - Avaliar se as respostas geradas estão em conformidade com a pergunta.\n",
    "3. **Registro das Fontes**:\n",
    "   - Analisar as fontes consultadas para garantir que apenas documentos relevantes foram utilizados.\n",
    "\n",
    "---\n",
    "\n",
    "## Resultados Esperados\n",
    "1. Respostas mais precisas e contextualizadas, diretamente relacionadas aos documentos corretos.\n",
    "2. Consultas à **LGPD** limitadas aos chunks de `lgpd.pdf`, eliminando interferências de fontes irrelevantes como `codigo_civil.pdf`.\n",
    "3. Melhor rastreabilidade das fontes devido aos metadados incluídos em cada chunk.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pergunta: definicao lei geral de protecao de dados\n",
      "\n",
      "Resposta Gerada:\n",
      "A Lei Geral de Proteção de Dados Pessoais (LGPD) define a proteção de dados pessoais como um direito fundamental que visa garantir a privacidade e a segurança dos indivíduos em relação à coleta, armazenamento e tratamento de suas informações pessoais. A LGPD estabelece regras e princípios para proteger os dados pessoais, incluindo:\n",
      "\n",
      "1. Princípio da transparência: é obrigatório informar o titular dos dados sobre a coleta, uso e compartilhamento de seus dados.\n",
      "2. Princípio da consentimento: é necessário obter o consentimento do titular para coletar, armazenar e tratar seus dados pessoais.\n",
      "3. Princípio da segurança: os dados pessoais devem ser protegidos contra acessos não autorizados, perda, dano ou destruição.\n",
      "4. Princípio da confidencialidade: os dados pessoais devem ser mantidos confidenciais e não compartilhados sem consentimento do titular.\n",
      "5. Princípio da responsabilidade: os controladores e operadores de dados são responsáveis por garantir a proteção dos dados pessoais.\n",
      "\n",
      "A LGPD também estabelece regras para a transferência internacional de dados pessoais, incluindo a necessidade de avaliar o nível de proteção de dados no país de destino ou no organismo internacional. Além disso, a lei estabelece regras para a responsabilidade e o ressarcimento de danos causados por violações da legislação de proteção de dados pessoais.\n",
      "\n",
      "Em resumo, a LGPD define a proteção de dados pessoais como um direito fundamental que visa garantir a privacidade e a segurança dos indivíduos em relação à coleta, armazenamento e tratamento de suas informações pessoais.\n",
      "\n",
      "Fontes:\n",
      "- lgpd.pdf\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fazer uma pergunta\n",
    "query1 = \"definicao lei geral de protecao de dados\"\n",
    "response1 = ask_question(query1, vectorstore_with_chunks)\n",
    "\n",
    "print(\"Pergunta:\", response1[\"question\"])\n",
    "print(\"\\nResposta Gerada:\")\n",
    "print(response1[\"response\"])\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nFontes:\")\n",
    "for source in set(response1[\"sources\"]):\n",
    "    print(\"-\", source)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pergunta: capitulo das perdas e danos?\n",
      "\n",
      "Resposta Gerada:\n",
      "O Capítulo III das Perdas e Danos.\n",
      "\n",
      "Fontes:\n",
      "- codigo_civil.pdf\n"
     ]
    }
   ],
   "source": [
    "query2 = \"capitulo das perdas e danos?\"\n",
    "response2 = ask_question(query2, vectorstore_with_chunks)\n",
    "\n",
    "print(\"Pergunta:\", response2[\"question\"])\n",
    "print(\"\\nResposta Gerada:\")\n",
    "print(response2[\"response\"])\n",
    "\n",
    "print(\"\\nFontes:\")\n",
    "for source in set(response2[\"sources\"]):\n",
    "    print(\"-\", source)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultados Após a Implementação dos Chunks\n",
    "\n",
    "## Observação\n",
    "Após dividir os documentos em **chunks**, refizemos as perguntas utilizando a nova pipeline. Com essa abordagem, conseguimos:\n",
    "\n",
    "1. **Recuperar as Fontes Corretamente**:\n",
    "   - As perguntas sobre a **LGPD** consultaram apenas os chunks relevantes de `lgpd.pdf`.\n",
    "   - Fontes irrelevantes, como o `codigo_civil.pdf`, não foram mais incluídas no contexto.\n",
    "\n",
    "2. **Respostas Mais Assertivas**:\n",
    "   - As respostas geradas pelo modelo foram mais precisas e alinhadas às perguntas feitas.\n",
    "   - A relevância e o contexto melhoraram significativamente devido ao uso de chunks menores e bem definidos.\n",
    "\n",
    "---\n",
    "\n",
    "## Benefícios Identificados\n",
    "1. **Melhor Foco no Contexto**:\n",
    "   - O sistema agora prioriza trechos específicos dos documentos, reduzindo a interferência de fontes não relacionadas.\n",
    "2. **Aumento na Precisão**:\n",
    "   - Respostas mais confiáveis e fundamentadas, com base em documentos diretamente relevantes ao tema da pergunta.\n",
    "3. **Rastreabilidade**:\n",
    "   - Cada resposta pode ser associada aos chunks e documentos específicos usados para gerar o contexto.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementação de Histórico na Interação com o Modelo\n",
    "\n",
    "## Objetivo\n",
    "Adicionar um histórico de conversas para que o modelo possa basear suas respostas em interações anteriores, fornecendo um contexto mais rico e um feedback mais assertivo.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_history_with_previous(history):\n",
    "    \"\"\"\n",
    "    Inclua todo o histórico, destacando explicitamente a interação mais recente.\n",
    "    \"\"\"\n",
    "    if not history:\n",
    "        return \"Histórico vazio.\"\n",
    "\n",
    "    # Última interação (pergunta e resposta anterior)\n",
    "    last_interaction = f\"Pergunta Anterior: {history[-1][0]}\\nResposta Anterior: {history[-1][1]}\"\n",
    "    \n",
    "    # Outras interações (exceto a última)\n",
    "    previous_interactions = \"\\n\".join([\n",
    "        f\"Pergunta: {q}\\nResposta: {r}\" for q, r in history[:-1]\n",
    "    ])\n",
    "    \n",
    "    # Combinar tudo\n",
    "    return f\"{previous_interactions}\\n\\n{last_interaction}\" if previous_interactions else last_interaction\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_prompt_with_history(query, context, history):\n",
    "\n",
    "    # Incluir o histórico completo\n",
    "    full_history = summarize_history_with_previous(history)\n",
    "    \n",
    "    # Destacar a última interação diretamente no contexto\n",
    "    if history:\n",
    "        last_question, last_answer = history[-1]\n",
    "        last_interaction_context = f\"Baseando-se na última interação:\\nPergunta: {last_question}\\nResposta: {last_answer}\\n\"\n",
    "    else:\n",
    "        last_interaction_context = \"\"\n",
    "\n",
    "    # Construir o prompt\n",
    "    prompt = f\"\"\"\n",
    "    Você é um assistente jurídico especializado no Código Civil brasileiro.\n",
    "\n",
    "    Última Interação:\n",
    "    {last_interaction_context}\n",
    "\n",
    "    Histórico de Conversa:\n",
    "    {full_history}\n",
    "\n",
    "    Trechos relevantes dos documentos:\n",
    "    {context}\n",
    "\n",
    "    Nova Pergunta:\n",
    "    {query}\n",
    "\n",
    "    Resposta:\n",
    "    \"\"\"\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def generate_response_with_history(query, vectorstore, history):\n",
    "\n",
    "    docs = vectorstore.similarity_search(query, k=5)\n",
    "    \n",
    "    context = \"\\n\\n\".join([\n",
    "        f\"Fonte: {doc.metadata.get('source', 'Desconhecido')}\\nTrecho: {doc.page_content[:300]}\" for doc in docs\n",
    "    ])\n",
    "    \n",
    "    \n",
    "    prompt = format_prompt_with_history(query, context, history)\n",
    "    \n",
    "    response = llm.invoke([prompt])\n",
    "    \n",
    "    history.append((query, response.content.strip()))\n",
    "    \n",
    "    output = {\n",
    "        \"question\": query,\n",
    "        \"response\": response.content.strip(),\n",
    "        \"sources\": [doc.metadata.get(\"source\", \"Desconhecido\") for doc in docs],\n",
    "        \"context_used\": context  \n",
    "    }\n",
    "    return output\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ask_question_with_history(query, vectorstore, history):\n",
    "\n",
    "    return generate_response_with_history(query, vectorstore, history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resposta Gerada:\n",
      "Olá! Estou aqui para ajudar.\n",
      "\n",
      "O Livro II do Código Civil brasileiro é dividido em várias seções, que abordam diferentes aspectos do direito privado. Aqui estão os capítulos e seções principais:\n",
      "\n",
      "**Capítulo I: Do Patrimônio**\n",
      "\n",
      "* Seção 1ª: Da propriedade\n",
      "* Seção 2ª: Da herança\n",
      "\n",
      "**Capítulo II: Das Pessoas Jurídicas de Direito Privado**\n",
      "\n",
      "* Seção 1ª: Da sociedade\n",
      "* Seção 2ª: Do testamento\n",
      "* Seção 3ª: Da sucessão\n",
      "* Seção 4ª: Da doação e da herança\n",
      "\n",
      "**Capítulo III: Das Obligações**\n",
      "\n",
      "* Seção 1ª: Da obrigação de fazer ou não fazer\n",
      "* Seção 2ª: Da obrigação de pagar\n",
      "* Seção 3ª: Da obrigação de entrega\n",
      "* Seção 4ª: Da obrigação de não fazer\n",
      "\n",
      "**Capítulo IV: Das Contratos**\n",
      "\n",
      "* Seção 1ª: Do contrato em geral\n",
      "* Seção 2ª: Do contrato de compra e venda\n",
      "* Seção 3ª: Do contrato de locação\n",
      "* Seção 4ª: Do contrato de trabalho\n",
      "\n",
      "Essas são as seções principais do Livro II do Código Civil. É importante notar que cada seção tem seus próprios capítulos e artigos, que detalham as regras e normas específicas para cada um desses aspectos do direito privado.\n",
      "\n",
      "Se você tiver mais alguma pergunta ou precisar de esclarecimentos sobre algum desses tópicos, estou aqui para ajudar!\n",
      "Fonte: codigo_civil.pdf\n",
      "Trecho:  que são objeto do Livro II da Parte Especial deste\n",
      "Código.\n",
      "Art. 45. Começa a existência legal das pessoas jurídicas de direito privado com\n",
      "a inscrição do ato constitutivo no respectivo registro, precedida, quando necessário,\n",
      "de autorização ou aprovação do Poder Executivo, averbando-se no registro t\n",
      "\n",
      "Fonte: codigo_civil.pdf\n",
      "Trecho: enciais, tais como o de eticidade, de socialidade e de operabilidade.\n",
      "542 Código Civil Brasileiro\n",
      "d) Aproveitamento dos trabalhos de reforma da Lei Civil, nas duas meritórias\n",
      "tentativas feitas, anteriormente, por ilustres jurisconsultos, primeiro por Hahneman\n",
      "Guimarães, Orozimbo Nonato e Philadelpho\n",
      "\n",
      "Fonte: codigo_civil.pdf\n",
      "Trecho: gou o capítulo sobre\n",
      "adoção especial, inscrito no Código de 1967” (Código Civile e Sistema Civilistico:\n",
      "II nucleo codicistico ed i suoi satelliti, in Rivista de Diritto Civile, Ano XXXIX, n.\n",
      "4, 1993, p. 403-413, cits. p. 406 e 410).\n",
      "Tem alcance amplo, portanto, a tendência redutora da importância do\n",
      "\n",
      "Fonte: codigo_civil.pdf\n",
      "Trecho:  a teses abstratas, visando a elaborar, sob a denominação de “Código\n",
      "Civil”, um “Código de Direito Privado”, o qual, se possível fora, seria de discutível\n",
      "utilidade ou conveniência.\n",
      "Na realidade, o que se realizou, no âmbito do Código Civil, foi a unidade do Di-\n",
      "reito das Obrigações, de conformidade\n",
      "\n",
      "Fonte: codigo_civil.pdf\n",
      "Trecho: 170 – É resgatável a enfiteuse instituída anteriormente à vigência do Código Civil.\n",
      "165 – A venda realizada diretamente pelo mandante ao mandatário não é atingida pela\n",
      "nulidade do art. 1.135, II, do Código Civil.\n",
      "163 – Salvo contra a Fazenda Pública, sendo a obrigação ilíquida, contam-se os juros\n",
      "mo\n",
      "\n",
      "Fontes:\n",
      "- codigo_civil.pdf\n"
     ]
    }
   ],
   "source": [
    "conversation_history = []\n",
    "\n",
    "response1 = ask_question_with_history(\n",
    "    \"Quais são os capítulos e seções do Livro II do Código Civil?\", \n",
    "    vectorstore_with_chunks, \n",
    "    conversation_history\n",
    ")\n",
    "\n",
    "print(\"\\nResposta Gerada:\")\n",
    "print(response1[\"response\"])\n",
    "print(response1[\"context_used\"])\n",
    "print(\"\\nFontes:\")\n",
    "for source in set(response1[\"sources\"]):\n",
    "    print(\"-\", source)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise da Resposta\n",
    "A resposta gerada está **incorreta**. Os capítulos e seções apresentados não correspondem ao conteúdo real do **Livro II do Código Civil brasileiro**.\n",
    "\n",
    "---\n",
    "\n",
    "## Próxima Ação: Passar a Definição Correta no Próximo Input\n",
    "Para corrigir o erro, vamos:\n",
    "1. **Inserir a definição correta** dos capítulos e seções do Livro II como parte do próximo input.\n",
    "2. **Atualizar o histórico** para que o modelo possa melhorar sua resposta com base no contexto correto.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resposta Gerada:\n",
      "Olá! Estou aqui para ajudar.\n",
      "\n",
      "Você está correto em dizer que os capítulos do Livro II do Código Civil são:\n",
      "\n",
      "**Livro II - Dos Bens**\n",
      "\n",
      "**Título Único - Das Diferentes Classes de Bens**\n",
      "\n",
      "**Capítulo I - Dos Bens Considerados em Si Mesmos**\n",
      "\n",
      "* Seção I - Dos Bens Imóveis\n",
      "* Seção II - Dos Bens Móveis\n",
      "* Seção III - Dos Bens Fungíveis e Consumíveis\n",
      "* Seção IV - Dos Bens Divisíveis\n",
      "* Seção V - Dos Bens Singulares e Coletivos\n",
      "\n",
      "**Capítulo II - Dos Bens Reciprocamente Considerados**\n",
      "\n",
      "* Capítulo III - Dos Bens Públicos\n",
      "\n",
      "Essas são as seções principais do Livro II do Código Civil, que abordam diferentes aspectos dos bens considerados em si mesmos e os bens públicos.\n",
      "\n",
      "Se você tiver mais alguma pergunta ou precisar de esclarecimentos sobre algum desses tópicos, estou aqui para ajudar!\n",
      "\n",
      "Fontes:\n",
      "- codigo_civil.pdf\n"
     ]
    }
   ],
   "source": [
    "response2 = ask_question_with_history(\n",
    "    '''Os capítulos do Livro II do Código Civil são Livro II – Dos Bens\n",
    "Título Único – Das Diferentes Classes de Bens\n",
    "\n",
    "Capítulo I – Dos Bens Considerados em Si Mesmos\n",
    "Seção I – Dos Bens Imóveis\n",
    "Seção II – Dos Bens Móveis\n",
    "Seção III – Dos Bens Fungíveis e Consumíveis\n",
    "Seção IV – Dos Bens Divisíveis\n",
    "Seção V – Dos Bens Singulares e Coletivos\n",
    "Capítulo II – Dos Bens Reciprocamente Considerados\n",
    "Capítulo III – Dos Bens Públicos''', \n",
    "    vectorstore_with_chunks, \n",
    "    conversation_history\n",
    ")\n",
    "\n",
    "print(\"\\nResposta Gerada:\")\n",
    "print(response2[\"response\"])\n",
    "print(\"\\nFontes:\")\n",
    "for source in set(response2[\"sources\"]):\n",
    "    print(\"-\", source)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reexecução da Pergunta com Feedback Fornecido\n",
    "\n",
    "## Contexto\n",
    "Após identificar que a resposta gerada anteriormente estava **incorreta**, fornecemos ao modelo o feedback necessário com a definição correta dos capítulos e seções do **Livro II do Código Civil**.\n",
    "\n",
    "---\n",
    "\n",
    "## Próxima Ação\n",
    "Agora, faremos a mesma pergunta novamente para verificar se o modelo:\n",
    "1. **Incorporou o feedback fornecido**.\n",
    "2. **Gera uma resposta correta** baseada no novo contexto.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Próximos Passos\n",
    "1. **Executar a pergunta novamente**.\n",
    "2. **Analisar a resposta gerada** para validar se ela corresponde ao contexto fornecido.\n",
    "3. Documentar os resultados e, se necessário, continuar ajustando o modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resposta Gerada:\n",
      "Olá! Estou aqui para ajudar.\n",
      "\n",
      "Os capítulos do Livro II do Código Civil são:\n",
      "\n",
      "**Livro II - Dos Bens**\n",
      "\n",
      "**Título Único - Das Diferentes Classes de Bens**\n",
      "\n",
      "**Capítulo I - Dos Bens Considerados em Si Mesmos**\n",
      "\n",
      "* Seção I - Dos Bens Imóveis\n",
      "* Seção II - Dos Bens Móveis\n",
      "* Seção III - Dos Bens Fungíveis e Consumíveis\n",
      "* Seção IV - Dos Bens Divisíveis\n",
      "* Seção V - Dos Bens Singulares e Coletivos\n",
      "\n",
      "**Capítulo II - Dos Bens Reciprocamente Considerados**\n",
      "\n",
      "* Capítulo III - Dos Bens Públicos\n",
      "\n",
      "Essas são as seções principais do Livro II do Código Civil, que abordam diferentes aspectos dos bens considerados em si mesmos e os bens públicos.\n",
      "\n",
      "Se você tiver mais alguma pergunta ou precisar de esclarecimentos sobre algum desses tópicos, estou aqui para ajudar!\n",
      "\n",
      "Fontes:\n",
      "- codigo_civil.pdf\n"
     ]
    }
   ],
   "source": [
    "response3 = ask_question_with_history(\n",
    "    \"Quais são os capítulos e seções do Livro II do Código Civil?\", \n",
    "    vectorstore_with_chunks, \n",
    "    conversation_history\n",
    ")\n",
    "\n",
    "print(\"\\nResposta Gerada:\")\n",
    "print(response3[\"response\"])\n",
    "print(\"\\nFontes:\")\n",
    "for source in set(response3[\"sources\"]):\n",
    "    print(\"-\", source)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uso do Histórico e Introdução ao Cross-Encoder\n",
    "\n",
    "## 1. Histórico Utilizado com Sucesso\n",
    "O uso do histórico na interação demonstrou ser eficaz para melhorar a precisão das respostas. Após fornecer o feedback necessário ao modelo e reutilizar o histórico, conseguimos obter a **resposta correta** para a pergunta:\n",
    "\n",
    "**Pergunta**: *\"Quais são os capítulos e seções do Livro II do Código Civil?\"*\n",
    "\n",
    "**Resposta Gerada**:  \n",
    "- **Livro II – Dos Bens**  \n",
    "- **Título Único – Das Diferentes Classes de Bens**\n",
    "\n",
    "### Benefícios do Histórico\n",
    "1. **Aprendizado Contínuo**: O modelo ajustou suas respostas com base no feedback e nas interações anteriores.\n",
    "2. **Melhoria na Precisão**: As respostas passaram a refletir melhor o contexto fornecido.\n",
    "3. **Contexto Rico**: O histórico permitiu ao modelo considerar informações adicionais e construir respostas mais completas.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Hipótese: Uso de Cross-Encoder para Melhorar a Rastreabilidade\n",
    "Podemos explorar o uso de um **cross-encoder** para refinar ainda mais o sistema. \n",
    "\n",
    "### O que é um Cross-Encoder?\n",
    "O cross-encoder é uma técnica de aprendizado profundo que:\n",
    "1. **Atribui pontuações de similaridade** diretamente entre a consulta e os trechos de texto recuperados.\n",
    "2. **Reavalia o contexto de maneira mais precisa** ao considerar todas as interações entre o texto e a consulta.\n",
    "\n",
    "### Benefícios Esperados do Cross-Encoder\n",
    "1. **Melhor Rastreabilidade**:\n",
    "   - O cross-encoder pode identificar com maior precisão os trechos mais relevantes, permitindo que o modelo utilize apenas os dados mais confiáveis.\n",
    "2. **Contexto Otimizado**:\n",
    "   - Refinando a seleção de trechos, o modelo terá um contexto mais relevante para gerar respostas.\n",
    "3. **Respostas Mais Precisas**:\n",
    "   - O uso de pontuações de similaridade permite ao sistema priorizar trechos que respondam diretamente à consulta, minimizando a interferência de informações secundárias.\n",
    "\n",
    "### Próximos Passos\n",
    "1. **Implementar o Cross-Encoder**:\n",
    "   - Integrar o modelo de cross-encoder para reavaliar os trechos recuperados antes de passá-los ao modelo.\n",
    "2. **Validar Hipótese**:\n",
    "   - Testar o impacto do cross-encoder na rastreabilidade e precisão das respostas.\n",
    "3. **Comparação com Resultados Anteriores**:\n",
    "   - Analisar as melhorias introduzidas pelo cross-encoder em relação ao uso do histórico sozinho.\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusão\n",
    "O uso do histórico melhorou significativamente as respostas do modelo, mas a introdução de um cross-encoder pode ser uma solução adicional para refinar ainda mais a rastreabilidade e precisão do sistema.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "\n",
    "def rerank_documents_with_crossencoder(query: str, docs: List, model_name: str = \"cross-encoder/ms-marco-MiniLM-L-6-v2\") -> List:\n",
    "    \"\"\"\n",
    "    Reorganiza os documentos usando um modelo CrossEncoder com base na relevância para a consulta.\n",
    "    \"\"\"\n",
    "    if not docs:\n",
    "        return []\n",
    "\n",
    "    # Inicializar o modelo CrossEncoder\n",
    "    cross_encoder = CrossEncoder(model_name)\n",
    "\n",
    "    # Criar pares de (query, document) para o modelo\n",
    "    query_doc_pairs = [(query, doc.page_content) for doc in docs]\n",
    "\n",
    "    # Obter scores de relevância\n",
    "    scores = cross_encoder.predict(query_doc_pairs)\n",
    "\n",
    "    # Ordenar os documentos pelo score em ordem decrescente\n",
    "    sorted_docs = [doc for _, doc in sorted(zip(scores, docs), key=lambda x: x[0], reverse=True)]\n",
    "\n",
    "    return sorted_docs\n",
    "\n",
    "\n",
    "\n",
    "def generate_response_with_rerank(query: str, vectorstore, history: List) -> dict:\n",
    "    \"\"\"\n",
    "    Gera uma resposta utilizando re-ranking dos documentos mais relevantes para a consulta.\n",
    "    \"\"\"\n",
    "    # Buscar mais documentos relevantes no Vectorstore\n",
    "    initial_docs = vectorstore.similarity_search(query, k=10)  # Aumentado para considerar mais documentos\n",
    "\n",
    "    if not initial_docs:\n",
    "        return {\n",
    "            \"question\": query,\n",
    "            \"response\": \"Nenhum documento relevante encontrado para a consulta.\",\n",
    "            \"sources\": [],\n",
    "            \"context_used\": \"\"\n",
    "        }\n",
    "\n",
    "    # Aplicar re-ranking nos documentos retornados\n",
    "    reranked_docs = rerank_documents_with_crossencoder(query, initial_docs)\n",
    "\n",
    "    # Selecionar os top 5 documentos após o re-ranking\n",
    "  \n",
    "\n",
    "    # Construir o contexto a partir dos documentos selecionados\n",
    "    context = \"\\n\\n\".join([\n",
    "        f\"Fonte: {doc.metadata.get('source', 'Desconhecido')}\\nTrecho: {doc.page_content}\" for doc in reranked_docs\n",
    "    ])\n",
    "\n",
    "    # Gerar o prompt com o histórico e contexto\n",
    "    #prompt \n",
    "\n",
    "    prompt = format_prompt_with_history(query, context, history)\n",
    "    # Obter a resposta do modelo LLM\n",
    "    response = llm.invoke([prompt])\n",
    "\n",
    "    # Adicionar a interação ao histórico\n",
    "    history.append((query, response.content.strip()))\n",
    "\n",
    "    # Formatar a saída\n",
    "    output = {\n",
    "        \"question\": query,\n",
    "        \"response\": response.content.strip(),\n",
    "        \"sources\": [doc.metadata.get(\"source\", \"Desconhecido\") for doc in reranked_docs],\n",
    "        \"context_used\": context\n",
    "    }\n",
    "    return output\n",
    "\n",
    "def ask_question_with_rerank(query: str, vectorstore, history: List) -> dict:\n",
    "    \"\"\"\n",
    "    Wrapper para gerar respostas com re-ranking utilizando o CrossEncoder.\n",
    "    \"\"\"\n",
    "    return generate_response_with_rerank(query, vectorstore, history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resposta Gerada:\n",
      "Infelizmente, não há uma resposta explícita na texto fornecido. No entanto, posso tentar ajudá-lo a identificar os capítulos e seções do Livro II do Código Civil brasileiro.\n",
      "\n",
      "O Livro II do Código Civil brasileiro é intitulado \"Das Pessoas\". Ele é dividido em 7 títulos:\n",
      "\n",
      "1. Título I: Da Personalidade\n",
      "\t* Seção I: Da Personalidade do Estado e de seus Cidadãos\n",
      "\t* Seção II: Do Estado e dos Cidadãos\n",
      "2. Título II: Da Família\n",
      "\t* Seção I: Da Matrimônio\n",
      "\t* Seção II: Da Adopção\n",
      "3. Título III: Das Sucessões\n",
      "\t* Seção I: Da Sucessão Legítima\n",
      "\t* Seção II: Da Sucessão Universal\n",
      "4. Título IV: Dos Testamentos\n",
      "5. Título V: Do Poder-Dele e do Mandato\n",
      "6. Título VI: Da Fideicomissão\n",
      "7. Título VII: Das Obligações\n",
      "\n",
      "Lembre-se de que a estrutura do Código Civil pode variar dependendo da edição e da interpretação dos dispositivos legais.\n",
      "Fonte: codigo_civil.pdf\n",
      "Trecho:  que são objeto do Livro II da Parte Especial deste\n",
      "Código.\n",
      "Art. 45. Começa a existência legal das pessoas jurídicas de direito privado com\n",
      "a inscrição do ato constitutivo no respectivo registro, precedida, quando necessário,\n",
      "de autorização ou aprovação do Poder Executivo, averbando-se no registro todas as\n",
      "alterações por que passar o ato constitutivo.\n",
      "Parágrafo único. Decai em três anos o direito de anular a constituição das pes-\n",
      "soas jurídicas de direito privado, por defeito do ato respectivo, contado o prazo da\n",
      "publicação de sua inscrição no registro.\n",
      "Art. 46. O registro declarará:\n",
      "I – a denominação, os fins, a sede, o tempo de duração e o fundo social,\n",
      "quando houver;\n",
      "56 Lei no 10.825/2003.\n",
      "Código Civil Brasileiro 149\n",
      "II – o nome e a individualização dos fundadores ou instituidores, e dos dire-\n",
      "tores;\n",
      "III – o modo por que se administra e representa, ativa e passivamente, judicial\n",
      "e extrajudicialmente;\n",
      "IV – se o ato constitutivo é reformável no tocante à administração, e de que\n",
      "modo;\n",
      "\n",
      "\n",
      "Fonte: codigo_civil.pdf\n",
      "Trecho:  “valiosas contribuições”, “tais como os An-\n",
      "Código Civil Brasileiro 533\n",
      "teprojetos de Código de Obrigações, de 1941 e de 1965”, “e o Anteprojeto de Código\n",
      "Civil, de 1963, de autoria do Prof. Orlando Gomes” (In Código Civil, 1o vol., Parte\n",
      "Geral – Pub. da Subsecretaria de Edições Técnicas do Senado Federal, Bras., 1975).\n",
      "5 – O relato do Professor Miguel Reale esclarece, ainda, e pertinentemente, que,\n",
      "“abandonada a linha de reforma que vinha sendo seguida”, ou seja, a de elaboração\n",
      "“de dois códigos distintos” – o Código Civil e o Código de Obrigações -, idéia que –\n",
      "acentua -” não logrou boa acolhida”, prevaleceu a orientação de feitura de um texto\n",
      "fundamental. Concisamente assevera que predominou, entre as diretrizes essenciais,\n",
      "a “compreensão do Código Civil como lei básica, mas não global, do Direito Priva-\n",
      "do, conservando-se em seu âmbito, por conseguinte, o Direito das Obrigações, sem\n",
      "distinção entre obrigações civis e mercantis”.\n",
      "6 – Veio ao Congresso Nacional, portanto, já unifica\n",
      "\n",
      "Fonte: codigo_civil.pdf\n",
      "Trecho:  que exercer permanentemente suas funções; o do\n",
      "militar, onde servir, e, sendo da Marinha ou da Aeronáutica, a sede do comando a\n",
      "que se encontrar imediatamente subordinado; o do marítimo, onde o navio estiver\n",
      "matriculado; e o do preso, o lugar em que cumprir a sentença.\n",
      "Art. 77. O agente diplomático do Brasil, que, citado no estrangeiro, alegar extrater-\n",
      "ritorialidade sem designar onde tem, no país, o seu domicílio, poderá ser demandado\n",
      "no Distrito Federal ou no último ponto do território brasileiro onde o teve.\n",
      "Art. 78. Nos contratos escritos, poderão os contratantes especificar domicílio onde\n",
      "se exercitem e cumpram os direitos e obrigações deles resultantes.\n",
      "Livro ii\n",
      "Dos Bens\n",
      "TÍTuLo úNiCo\n",
      "Das Diferentes Classes de Bens\n",
      "CAPÍTuLo i\n",
      "Dos Bens Considerados em Si Mesmos\n",
      "SEção i\n",
      "Dos Bens Imóveis\n",
      "Art. 79. São bens imóveis o solo e tudo quanto se lhe incorporar natural ou arti-\n",
      "ficialmente.\n",
      "Art. 80. Consideram-se imóveis para os efeitos legais:\n",
      "154 Código Civil Brasileiro\n",
      "I – os direitos reai\n",
      "\n",
      "Fonte: codigo_civil.pdf\n",
      "Trecho: enciais, tais como o de eticidade, de socialidade e de operabilidade.\n",
      "542 Código Civil Brasileiro\n",
      "d) Aproveitamento dos trabalhos de reforma da Lei Civil, nas duas meritórias\n",
      "tentativas feitas, anteriormente, por ilustres jurisconsultos, primeiro por Hahneman\n",
      "Guimarães, Orozimbo Nonato e Philadelpho de Azevedo, com o anteprojeto do “Có-\n",
      "digo das Obrigações”; e, depois, por Orlando Gomes e Caio Mario da Silva Pereira,\n",
      "com a proposta de elaboração separada de um Código Civil e de um Código das\n",
      "Obrigações, contando com a colaboração, neste caso, de Silvio Marcondes, Theóphilo\n",
      "de Azevedo Santos e Nehemias Gueiros.\n",
      "e) Firmar a orientação de somente inserir no Código matéria já consolidada ou\n",
      "com relevante grau de experiência crítica, transferindo-se para a legislação especial\n",
      "aditiva o regramento de questões ainda em processo de estudo, ou que, por sua natureza\n",
      "complexa, envolvem problemas e soluções que extrapolam do Código Civil.\n",
      "f) Dar nova estrutura ao Código, mantendo-se a Parte Geral \n",
      "\n",
      "Fonte: codigo_civil.pdf\n",
      "Trecho: BrE o\n",
      "ProJETo DE CÓDiGo CiviL\n",
      "Josaphat Marinho – Relator-Geral\n",
      "Sumário\n",
      "Breve histórico – Providência frustrada – Observações preliminares – Direito sem\n",
      "unidade – Codificação – Declínio da codificação. Leis especiais – O problema no\n",
      "Brasil – Outras razões ponderáveis – Prudência e flexibilidade – Novos subsídios.\n",
      "Breve histórico\n",
      "1 – A iniciativa, propriamente dita, da elaboração de novo Código Civil coube ao\n",
      "governo Jânio Quadros, cujo Ministro da Justiça, Oscar Pedroso d’Horta, confiou o\n",
      "preparo de anteprojeto, em 1961, ao Professor Orlando Gomes. Pouco após o começo\n",
      "do trabalho do jurista baiano, sobreveio a renúncia do presidente da República.\n",
      "2 – No governo João Goulart, o Ministro da Justiça João Mangabeira, em outubro\n",
      "de 1962, retomou o estudo da matéria, renovando a confiança no professor Orlando\n",
      "Gomes, que apresentou o Anteprojeto em março de 1963. Submetido a uma Comissão\n",
      "Revisora, que participaram, com o autor, o Ministro Orozimbo Nonato e o professor\n",
      "Caio Mário da Silva Perei\n",
      "\n",
      "Fonte: codigo_civil.pdf\n",
      "Trecho: .........204\n",
      "Capítulo IV – Da Doação\n",
      "Seção I – Disposições Gerais ......................................................................204\n",
      "Seção II – Da Revogação da Doação ..........................................................206\n",
      "Capítulo V – Da Locação de Coisas ...............................................................207\n",
      "Capítulo VI – Do Empréstimo\n",
      "Seção I – Do Comodato ...............................................................................209\n",
      "Seção II – Do Mútuo ...................................................................................209\n",
      "Capítulo VII – Da Prestação de Serviço .........................................................210\n",
      "Capítulo VIII – Da Empreitada ......................................................................212\n",
      "Capítulo IX – Do Depósito\n",
      "Seção I – Do Depósito Voluntário ...............................................................214\n",
      "Seção II – Do Depósito Necessário ...........................................................\n",
      "\n",
      "Fonte: codigo_civil.pdf\n",
      "Trecho: a reforma das es-\n",
      "truturas devesse ser cumprida através da substituição do Código Civil”, nem por isso\n",
      "confundiu “o problema da reforma com o problema da codificação”. E explicou: “A\n",
      "reforma pode ser gradualmente realizada mediante a introdução no sistema jurídico\n",
      "de leis que modificam institutos codificados ou que exprimem a filosofia da mudança,\n",
      "remediando a crise de legitimidade”. Anota que uma visão das leis especiais editadas\n",
      "Código Civil Brasileiro 537\n",
      "no Brasil, a partir de 1930, permite o mapeamento das partes necrosadas do código,\n",
      "já substituídas por outras”, dotadas de funcionalidade, e indica o Código de Águas,\n",
      "o Código de Minas, o Código Florestal, o Código de Menores, e à frente deles, pela\n",
      "idade e pela importância, a Consolidação das Leis do Trabalho”. Realçando as “tensões\n",
      "e contradições da civilização industrial dos dias correntes”, entende que “a substitui-\n",
      "ção global de um Código Civil é atualmente um anacronismo”. Reforça a tese para\n",
      "considerar decisão dessa natureza\n",
      "\n",
      "Fonte: codigo_civil.pdf\n",
      "Trecho: essor Orlando\n",
      "Gomes, que apresentou o Anteprojeto em março de 1963. Submetido a uma Comissão\n",
      "Revisora, que participaram, com o autor, o Ministro Orozimbo Nonato e o professor\n",
      "Caio Mário da Silva Pereira, e sujeito a debate em instituições de cultura, o Anteprojeto\n",
      "foi entregue, solenemente, em 28 de setembro de 1963, ao Ministro da Justiça Milton\n",
      "Campos, já no governo Castello Branco.\n",
      "É o que, resumidamente, informa o professor Orlando Gomes no livro “A Reforma\n",
      "do Código Civil (Publs. da Univ. da Bahia, 1965).\n",
      "3 – Em maio de 1969, foi constituída “Comissão Revisora e Elaboradora do\n",
      "Código Civil”, composta dos professores Miguel Reale, na qualidade de Supervisor,\n",
      "José Carlos Moreira Alves, Agostinho de Arruda Alvim, Sylvio Marcondes, Ebert\n",
      "Chamoun, Clovis do Couto e Silva e Torquato Castro, de cujos estudos “resultou\n",
      "novo Anteprojeto, publicado em 18 de junho de 1974”.\n",
      "Eis o que noticia a exposição de motivos do Ministro da Justiça Armando Falcão,\n",
      "de 1975, dirigida ao presidente Ernesto\n",
      "\n",
      "Fonte: codigo_civil.pdf\n",
      "Trecho: as rodoviária e ferroviária\n",
      "federais;\n",
      "XXIII – seguridade social;\n",
      "XXIV – diretrizes e bases da educação nacional;\n",
      "XXV – registros públicos;\n",
      "XXVI – atividades nucleares de qualquer natureza;\n",
      "XXVII – normas gerais de licitação e contratação, em todas as modalidades,\n",
      "para as administrações públicas diretas, autárquicas e fundacionais da União, Estados,\n",
      "Distrito Federal e Municípios, obedecido o disposto no art. 37, XXI, e para as empresas\n",
      "públicas e sociedades de economia mista, nos termos do art. 173, §1o, III;\n",
      "XXVIII – defesa territorial, defesa aeroespacial, defesa marítima, defesa civil\n",
      "e mobilização nacional;\n",
      "XXIX – propaganda comercial.\n",
      "Código Civil Brasileiro 31\n",
      "Parágrafo único. Lei complementar poderá autorizar os Estados a legislar sobre\n",
      "questões específicas das matérias relacionadas neste artigo.\n",
      "Art. 23. É competência comum da União, dos Estados, do Distrito Federal e dos\n",
      "Municípios:9\n",
      "I – zelar pela guarda da Constituição, das leis e das instituições democráticas\n",
      "e conservar o p\n",
      "\n",
      "Fonte: codigo_civil.pdf\n",
      "Trecho: condição, a lei poderá permitir que outras causas sejam também\n",
      "processadas e julgadas pela Justiça estadual.\n",
      "§ 4o Na hipótese do parágrafo anterior, o recurso cabível será sempre para o Tri-\n",
      "bunal Regional Federal na área de jurisdição do juiz de primeiro grau.\n",
      "§ 5o Nas hipóteses de grave violação de direitos humanos, o Procurador-Geral da\n",
      "República, com a finalidade de assegurar o cumprimento de obrigações decorrentes\n",
      "de tratados internacionais de direitos humanos dos quais o Brasil seja parte, poderá\n",
      "suscitar, perante o Superior Tribunal de Justiça, em qualquer fase do inquérito ou\n",
      "processo, incidente de deslocamento de competência para a Justiça Federal.\n",
      "50 Código Civil Brasileiro\n",
      "Art. 110. Cada Estado, bem como o Distrito Federal, constituirá uma seção judiciá-\n",
      "ria, que terá por sede a respectiva capital, e varas localizadas segundo o estabelecido\n",
      "em lei.\n",
      "Parágrafo único. Nos Territórios Federais, a jurisdição e as atribuições cometidas\n",
      "aos juízes federais caberão aos juízes da Jus\n",
      "\n",
      "Fontes:\n",
      "- codigo_civil.pdf\n"
     ]
    }
   ],
   "source": [
    "conversation_history = []\n",
    "\n",
    "response1 = ask_question_with_rerank(\n",
    "    \"Quais são os capítulos e seções do Livro II do Código Civil brasileiro?\", \n",
    "    vectorstore_with_chunks, \n",
    "    conversation_history\n",
    "    \n",
    ")\n",
    "\n",
    "print(\"\\nResposta Gerada:\")\n",
    "print(response1[\"response\"])\n",
    "print(response1[\"context_used\"])\n",
    "print(\"\\nFontes:\")\n",
    "for source in set(response1[\"sources\"]):\n",
    "    print(\"-\", source)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultados do Uso de Rerank na Recuperação de Contexto\n",
    "\n",
    "## Observação\n",
    "Com a introdução do **rerank** no pipeline. A técnica conseguiu priorizar trechos que mencionam mais diretamente a **keyword \"Livro II\"**, resultando em um contexto mais relevante para a pergunta.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Limitações Identificadas\n",
    "Apesar da melhoria no contexto recuperado, a **resposta gerada pelo modelo ainda está incorreta**. Isso pode indicar:\n",
    "1. **Interpretação Limitada do Modelo**:\n",
    "   - O modelo não está aproveitando plenamente o contexto priorizado pelo rerank.\n",
    "2. **Necessidade de Ajustes no Contexto**:\n",
    "   - O contexto, embora relevante, pode não estar detalhado o suficiente para auxiliar o modelo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resposta Gerada:\n",
      "Os capítulos do Livro II do Código Civil são:\n",
      "\n",
      "1. Capítulo I - Dos Bens Considerados em Si Mesmos\n",
      "   - Seção I - Dos Bens Imóveis\n",
      "   - Seção II - Dos Bens Móveis\n",
      "   - Seção III - Dos Bens Fungíveis e Consumíveis\n",
      "   - Seção IV - Dos Bens Divisíveis\n",
      "   - Seção V - Dos Bens Singulares e Coletivos\n",
      "\n",
      "2. Capítulo II - Dos Bens Reciprocamente Considerados\n",
      "\n",
      "3. Capítulo III - Dos Bens Públicos\n",
      "\n",
      "Fontes:\n",
      "- codigo_civil.pdf\n"
     ]
    }
   ],
   "source": [
    "response2 = ask_question_with_rerank(\n",
    "    '''Os capítulos do Livro II do Código Civil são Livro II – Dos Bens\n",
    "Título Único – Das Diferentes Classes de Bens\n",
    "\n",
    "Capítulo I – Dos Bens Considerados em Si Mesmos\n",
    "Seção I – Dos Bens Imóveis\n",
    "Seção II – Dos Bens Móveis\n",
    "Seção III – Dos Bens Fungíveis e Consumíveis\n",
    "Seção IV – Dos Bens Divisíveis\n",
    "Seção V – Dos Bens Singulares e Coletivos\n",
    "Capítulo II – Dos Bens Reciprocamente Considerados\n",
    "Capítulo III – Dos Bens Públicos''', \n",
    "    vectorstore_with_chunks, \n",
    "    conversation_history\n",
    ")\n",
    "\n",
    "print(\"\\nResposta Gerada:\")\n",
    "print(response2[\"response\"])\n",
    "print(\"\\nFontes:\")\n",
    "for source in set(response2[\"sources\"]):\n",
    "    print(\"-\", source)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resposta Gerada:\n",
      "Infelizmente não consegui encontrar as informações solicitadas.\n",
      "\n",
      "Fontes:\n",
      "- codigo_civil.pdf\n"
     ]
    }
   ],
   "source": [
    "response3 = ask_question_with_rerank(\n",
    "    \"Quais são os capítulos e seções do Livro II do Código Civil?\", \n",
    "    vectorstore_with_chunks, \n",
    "    conversation_history\n",
    ")\n",
    "\n",
    "print(\"\\nResposta Gerada:\")\n",
    "print(response3[\"response\"])\n",
    "print(\"\\nFontes:\")\n",
    "for source in set(response3[\"sources\"]):\n",
    "    print(\"-\", source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise: Histórico e Rerank\n",
    "\n",
    "## Observação Geral\n",
    "Embora tenhamos introduzido o uso do histórico e do rerank para melhorar a recuperação de contexto e a precisão das respostas, o modelo apresentou limitações em interações mais longas e iterativas. Na terceira pergunta, mesmo após o feedback fornecido, o modelo **não conseguiu encontrar a resposta correta**.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdução ao Uso de Metadados na Recuperação de Documentos\n",
    "\n",
    "## Objetivo\n",
    "Melhorar a rastreabilidade e precisão na recuperação de informações ao:\n",
    "1. **Incluir metadados** como Livro, Capítulo e Seção em cada chunk extraído dos documentos.\n",
    "2. Estruturar os chunks de forma mais granular, associando cada parte do texto aos seus respectivos metadados.\n",
    "\n",
    "---\n",
    "## Hipotese\n",
    "1. Preparar um vetorstore utilizando documentos com metadados para consultas mais precisas.\n",
    "---\n",
    "\n",
    "## Beneficio\n",
    "1. Facilitar a rastreabilidade, associando cada chunk aos metadados contextuais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def split_chunks_v2(text, chunk_size=1000, overlap=200):\n",
    "\n",
    "    # Padrões para detectar Livro, Capítulo e Seção (case-insensitive)\n",
    "    livro_pattern = re.compile(r\"(Livro\\s+[IVXLCDM\\d]+\\s*.*?)\\s*(?=\\n|$)\", re.IGNORECASE)\n",
    "    capitulo_pattern = re.compile(r\"(Capítulo\\s+[IVXLCDM\\d]+\\s*.*?)\\s*(?=\\n|$)\", re.IGNORECASE)\n",
    "    secao_pattern = re.compile(r\"(Seção\\s+[IVXLCDM\\d]+\\s*.*?)\\s*(?=\\n|$)\", re.IGNORECASE)\n",
    "\n",
    "    # Variáveis para acompanhar os metadados atuais\n",
    "    current_livro = None\n",
    "    current_capitulo = None\n",
    "    current_secao = None\n",
    "\n",
    "    # Lista de chunks e variáveis de controle\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_size = 0\n",
    "\n",
    "    def save_chunk_and_reset():\n",
    "        nonlocal current_chunk, current_size\n",
    "        if current_chunk:\n",
    "            chunks.append({\n",
    "                \"content\": \"\\n\".join(current_chunk),\n",
    "                \"metadata\": {\n",
    "                    \"livro\": current_livro,\n",
    "                    \"capítulo\": current_capitulo,\n",
    "                    \"seção\": current_secao\n",
    "                }\n",
    "            })\n",
    "            # Reiniciar mantendo o overlap\n",
    "            current_chunk = current_chunk[-overlap:]\n",
    "            current_size = sum(len(line) for line in current_chunk)\n",
    "\n",
    "    # Processar linhas do texto\n",
    "    for line in text.split(\"\\n\"):\n",
    "        # Detectar mudanças nos metadados\n",
    "        if livro_match := livro_pattern.match(line):\n",
    "            save_chunk_and_reset()\n",
    "            current_livro = livro_match.group(1)\n",
    "\n",
    "        if capitulo_match := capitulo_pattern.match(line):\n",
    "            save_chunk_and_reset()\n",
    "            current_capitulo = capitulo_match.group(1)\n",
    "\n",
    "        if secao_match := secao_pattern.match(line):\n",
    "            save_chunk_and_reset()\n",
    "            current_secao = secao_match.group(1)\n",
    "\n",
    "        # Adicionar linha ao chunk atual\n",
    "        current_chunk.append(line)\n",
    "        current_size += len(line)\n",
    "\n",
    "        # Criar chunk se atingir o tamanho definido\n",
    "        if current_size >= chunk_size:\n",
    "            save_chunk_and_reset()\n",
    "\n",
    "    # Adicionar o último chunk\n",
    "    save_chunk_and_reset()\n",
    "\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "def load_pdf_documents_v2(pdf_paths, chunk_size=1000, overlap=200):\n",
    "\n",
    "    documents = []\n",
    "    \n",
    "    for pdf_path in pdf_paths:\n",
    "        try:\n",
    "            # Abrir o PDF\n",
    "            with pdfplumber.open(pdf_path) as pdf:\n",
    "                print(f\"Processando arquivo: {pdf_path}\")\n",
    "                for page_number, page in enumerate(pdf.pages, start=1):\n",
    "                    # Extrair texto da página\n",
    "                    text = page.extract_text()\n",
    "                    \n",
    "                    if text:\n",
    "\n",
    "\n",
    "                        # Dividir o texto em chunks\n",
    "                        chunks = split_chunks_v2(text, chunk_size, overlap)\n",
    "                        \n",
    "                        if not chunks:\n",
    "                            continue\n",
    "                        \n",
    "                        # Adicionar chunks à lista de documentos\n",
    "                        for chunk in chunks:\n",
    "                            documents.append(Document(\n",
    "                                page_content=chunk[\"content\"],\n",
    "                                metadata={\n",
    "                                    \"source\": pdf_path,\n",
    "                                    \"page\": page_number,\n",
    "                                    **chunk[\"metadata\"]  # Inclui metadados como Livro, Capítulo, Seção\n",
    "                                }\n",
    "                            ))\n",
    "                    else:\n",
    "                            pass\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao processar o arquivo {pdf_path}: {e}\")\n",
    "    \n",
    "    if not documents:\n",
    "        print(\"Nenhum documento foi carregado. Verifique os arquivos PDF ou os métodos de extração.\")\n",
    "    else:\n",
    "        print(f\"Carregados {len(documents)} documentos do total de {len(pdf_paths)} arquivos PDF.\")\n",
    "\n",
    "    return documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_vectorstore_with_chunks_v2(pdf_paths, chunk_size=2000, overlap=300):\n",
    "    # Carregar documentos estruturados com resumos\n",
    "    documents = load_pdf_documents_v2(pdf_paths, chunk_size, overlap)\n",
    "\n",
    "    # Criar vetorstore\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    vectorstore = FAISS.from_documents(documents, embeddings)\n",
    "    \n",
    "    return [vectorstore, documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando arquivo: data/lgpd.pdf\n",
      "Processando arquivo: data/codigo_civil.pdf\n",
      "Carregados 4519 documentos do total de 2 arquivos PDF.\n"
     ]
    }
   ],
   "source": [
    "vectorstore_with_chunks_v, documents = prepare_vectorstore_with_chunks_v2(pdf_files, chunk_size=2000, overlap=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2194/979482863.py:14: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = qa_chain({\"question\": question, \"chat_history\": conversation_history})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resposta Gerada:\n",
      "As perdas e danos são conceitos importantes na teoria jurídica, especialmente no direito civil. Aqui está uma explicação detalhada sobre o que são perdas e danos:\n",
      "\n",
      "**O que são perdas?**\n",
      "\n",
      "As perdas são os prejuízos ou consequências negativas que alguém sofre como resultado de um ato ou ação de outra pessoa. São consideradas como parte do dano moral e material que a vítima sofreu.\n",
      "\n",
      "**Tipos de perdas**\n",
      "\n",
      "Existem dois tipos principais de perdas:\n",
      "\n",
      "1. **Perdas materiais**: são os prejuízos financeiros ou econômicos que a vítima sofreu, como danos à propriedade, perda de renda, etc.\n",
      "2. **Perdas morais**: são os prejuízos emocionais e psicológicos que a vítima sofreu, como dor, angústia, estresse, etc.\n",
      "\n",
      "**O que são danos?**\n",
      "\n",
      "Os danos são as consequências negativas que alguém sofre como resultado de um ato ou ação de outra pessoa. São consideradas como parte do dano moral e material que a vítima sofreu.\n",
      "\n",
      "**Tipos de danos**\n",
      "\n",
      "Existem dois tipos principais de danos:\n",
      "\n",
      "1. **Dano material**: é o prejuízo econômico ou financeiro que a vítima sofreu, como danos à propriedade, perda de renda, etc.\n",
      "2. **Dano moral**: é o prejuízo emocional e psicológico que a vítima sofreu, como dor, angústia, estresse, etc.\n",
      "\n",
      "**Exemplos**\n",
      "\n",
      "* Se alguém é atropelado por um carro e sofre danos físicos e morais, as perdas e danos incluem:\n",
      " + Perda de renda devido à incapacidade de trabalhar\n",
      " + Danos à propriedade do veículo\n",
      " + Dor e angústia emocional\n",
      "* Se alguém é vítima de um acidente de trabalho e sofre danos físicos e morais, as perdas e danos incluem:\n",
      " + Perda de renda devido à incapacidade de trabalhar\n",
      " + Danos à saúde e bem-estar\n",
      " + Dor e angústia emocional\n",
      "\n",
      "**Conclusão**\n",
      "\n",
      "As perdas e danos são conceitos importantes na teoria jurídica, especialmente no direito civil. São consideradas como parte do dano moral e material que a vítima sofreu. É fundamental entender os tipos de perdas e danos para poder avaliar as consequências negativas que alguém sofreu como resultado de um ato ou ação de outra pessoa.\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Primeiro Contexto Utilizado:\n",
      "Livro: None\n",
      "Capítulo: CAPÍTuLo iii\n",
      "Seção: None\n",
      "Conteúdo:\n",
      " CAPÍTuLo iii\n",
      "Das Perdas e Danos\n",
      "Art. 402. Salvo as exceções expressamente previstas em lei, as perdas e danos\n",
      "devidas ao credor abrangem, além do que ele efetivamente perdeu, o que razoavel-\n",
      "mente deixou de lucrar.\n",
      "Art. 403. Ainda que a inexecução resulte de dolo do devedor, as perdas e danos só\n",
      "incluem os prejuízos efetivos e os lucros cessantes por efeito dela direto e imediato,\n",
      "sem prejuízo do disposto na lei processual.\n",
      "Art. 404. As perdas e danos, nas obrigações de pagamento em dinheiro, serão pagas\n",
      "com atualização monetária segundo índices oficiais regularmente estabelecidos, abran-\n",
      "gendo juros, custas e honorários de advogado, sem prejuízo da pena convencional.\n",
      "Parágrafo único. Provado que os juros da mora não cobrem o prejuízo, e não ha-\n",
      "vendo pena convencional, pode o juiz conceder ao credor indenização suplementar.\n",
      "Art. 405. Contam-se os juros de mora desde a citação inicial.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def ask_question_with_history_v2(question, vectorstore, conversation_history):\n",
    "\n",
    "    from langchain.chains import ConversationalRetrievalChain\n",
    "    from langchain.chains.question_answering import load_qa_chain\n",
    "    from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "\n",
    "    qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "        llm=llm,\n",
    "        retriever=vectorstore.as_retriever(),\n",
    "        return_source_documents=True  # Garante que as fontes sejam retornadas\n",
    "    )\n",
    "\n",
    "    result = qa_chain({\"question\": question, \"chat_history\": conversation_history})\n",
    "\n",
    "    conversation_history.append((question, result[\"answer\"]))\n",
    "\n",
    "    metadata_list = []\n",
    "    for doc in result[\"source_documents\"]:\n",
    "        metadata = doc.metadata\n",
    "        metadata_list.append({\n",
    "            \"livro\": metadata.get(\"livro\"),\n",
    "            \"capítulo\": metadata.get(\"capítulo\"),\n",
    "            \"seção\": metadata.get(\"seção\"),\n",
    "            \"content\": doc.page_content  \n",
    "        })\n",
    "\n",
    "    return {\n",
    "        \"response\": result[\"answer\"],\n",
    "        \"context_used\": metadata_list,\n",
    "    }\n",
    "\n",
    "\n",
    "# Exemplo de uso\n",
    "conversation_history = []\n",
    "response1 = ask_question_with_history_v2(\n",
    "    \"Perdas e danos\",\n",
    "    vectorstore_with_chunks_v,\n",
    "    conversation_history\n",
    ")\n",
    "\n",
    "# Exibir resposta e contexto\n",
    "print(\"\\nResposta Gerada:\")\n",
    "print(response1[\"response\"])\n",
    "\n",
    "print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "# print(\"Contexto utilizado:\")\n",
    "# for context in response1[\"context_used\"]:\n",
    "#     print(f\"Livro: {context['livro']}\")\n",
    "#     print(f\"Capítulo: {context['capítulo']}\")\n",
    "#     print(f\"Seção: {context['seção']}\")\n",
    "#     print(\"Conteúdo:\\n\", context[\"content\"])\n",
    "#     print(\"\\n---\\n\")\n",
    "print(\"Primeiro Contexto Utilizado:\")\n",
    "if response1[\"context_used\"]:\n",
    "    first_context = response1[\"context_used\"][0]\n",
    "    print(f\"Livro: {first_context['livro']}\")\n",
    "    print(f\"Capítulo: {first_context['capítulo']}\")\n",
    "    print(f\"Seção: {first_context['seção']}\")\n",
    "    print(\"Conteúdo:\\n\", first_context[\"content\"])\n",
    "else:\n",
    "    print(\"Nenhum contexto foi utilizado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Análise\n",
    "\n",
    "### Metadados\n",
    "- **Capítulo**: O modelo identificou corretamente o **Capítulo III – Das Perdas e Danos** como relevante.\n",
    "- **Livro e Seção**: Não foram detectados metadados específicos, mas o capítulo principal foi recuperado com sucesso.\n",
    "\n",
    "### Contexto\n",
    "- O conteúdo recuperado cita diretamente os artigos legais que tratam de perdas e danos.\n",
    "- A precisão do contexto alinhou-se à pergunta, proporcionando uma base sólida para a resposta.\n",
    "\n",
    "### Resposta\n",
    "- A resposta gerada foi bem detalhada e consistente com o contexto jurídico recuperado.\n",
    "- Incluiu explicações adicionais sobre perdas e danos, tipos e cálculo.\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusão\n",
    "O uso de metadados melhorou a **rastreamento** e a **relevância do contexto** recuperado. O modelo foi capaz de identificar o **Capítulo III – Das Perdas e Danos** e utilizá-lo para construir uma resposta clara e detalhada. Essa abordagem reforça a importância de estruturar documentos com metadados para consultas mais precisas e contextualizadas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "melhorando os metadados usando mais metadados de ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pdfplumber\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "# Função para dividir o texto em chunks e gerar metadados com NMF\n",
    "def split_chunks_with_ml_metadata(text, chunk_size=2000, overlap=300, page_number=None, source=None):\n",
    "\n",
    "    current_chunk = []\n",
    "    chunks = []\n",
    "    current_size = 0\n",
    "    chunk_index = 0\n",
    "    line_start = 1\n",
    "\n",
    "    def save_chunk_and_reset(line_end):\n",
    "        nonlocal current_chunk, current_size, chunk_index, line_start\n",
    "        if current_chunk:\n",
    "            content = \"\\n\".join(current_chunk)\n",
    "            metadata = extract_topics_with_nmf(content)\n",
    "            metadata.update({\n",
    "                \"linha_inicio\": line_start,\n",
    "                \"linha_fim\": line_end,\n",
    "                \"pagina\": page_number,\n",
    "                \"source\": source\n",
    "            })\n",
    "            chunks.append({\n",
    "                \"chunk_index\": chunk_index,\n",
    "                \"content\": content,\n",
    "                \"metadata\": metadata\n",
    "            })\n",
    "            chunk_index += 1\n",
    "            line_start = line_end - len(current_chunk) + 1\n",
    "            current_chunk = current_chunk[-overlap:]\n",
    "            current_size = sum(len(line) for line in current_chunk)\n",
    "\n",
    "    for i, line in enumerate(text.split(\"\\n\"), start=1):\n",
    "        current_chunk.append(line)\n",
    "        current_size += len(line)\n",
    "\n",
    "        if current_size >= chunk_size:\n",
    "            save_chunk_and_reset(i)\n",
    "\n",
    "    save_chunk_and_reset(len(text.split(\"\\n\")))\n",
    "\n",
    "    return chunks\n",
    "\n",
    "# Função para extrair tópicos com NMF\n",
    "def extract_topics_with_nmf(content, n_topics=2):\n",
    "    if not content.strip():\n",
    "        return {\"topico_1\": None, \"topico_2\": None}\n",
    "\n",
    "    vectorizer = TfidfVectorizer(stop_words=\"portuguese\")\n",
    "    try:\n",
    "        X = vectorizer.fit_transform([content])\n",
    "\n",
    "        if X.shape[0] == 0 or X.shape[1] == 0:\n",
    "            return {\"topico_1\": None, \"topico_2\": None}\n",
    "\n",
    "        nmf = NMF(n_components=n_topics, random_state=42, init='nndsvd', max_iter=500, tol=1e-4)\n",
    "        W = nmf.fit_transform(X)\n",
    "        H = nmf.components_\n",
    "        terms = vectorizer.get_feature_names_out()\n",
    "\n",
    "        topics = []\n",
    "        for topic_idx, topic in enumerate(H):\n",
    "            top_terms = [terms[i] for i in topic.argsort()[:-5 - 1:-1]]\n",
    "            topics.append(\" \".join(top_terms))\n",
    "\n",
    "        return {\n",
    "            \"topico_1\": topics[0] if len(topics) > 0 else None,\n",
    "            \"topico_2\": topics[1] if len(topics) > 1 else None\n",
    "        }\n",
    "    except ValueError as e:\n",
    "        print(f\"Erro de entrada nos dados: {e}\")\n",
    "        return {\"topico_1\": None, \"topico_2\": None}\n",
    "    except Exception as e:\n",
    "        print(f\"Erro no NMF: {e}\")\n",
    "        return {\"topico_1\": None, \"topico_2\": None}\n",
    "\n",
    "\n",
    "# Função para carregar PDFs e dividir em chunks\n",
    "def load_and_chunk_pdfs_with_ml_metadata(pdf_paths, chunk_size=2000, overlap=300):\n",
    "    documents = []\n",
    "\n",
    "    for pdf_path in pdf_paths:\n",
    "        try:\n",
    "            with pdfplumber.open(pdf_path) as pdf:\n",
    "                for page_number, page in enumerate(pdf.pages, start=1):\n",
    "                    text = page.extract_text()\n",
    "                    if text:\n",
    "                        chunks = split_chunks_with_ml_metadata(\n",
    "                            text, chunk_size, overlap, page_number=page_number, source=pdf_path\n",
    "                        )\n",
    "                        for chunk in chunks:\n",
    "                            documents.append(Document(\n",
    "                                page_content=chunk[\"content\"],\n",
    "                                metadata=chunk[\"metadata\"]\n",
    "                            ))\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "    return documents\n",
    "\n",
    "# Função para criar o vetorstore\n",
    "def create_vectorstore_with_metadata(documents):\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    vectorstore = FAISS.from_documents(documents, embeddings)\n",
    "    return vectorstore\n",
    "\n",
    "# Função principal para todo o fluxo\n",
    "def prepare_vectorstore_from_pdfs_with_ml(pdf_paths, chunk_size=2000, overlap=300):\n",
    "    documents = load_and_chunk_pdfs_with_ml_metadata(pdf_paths, chunk_size, overlap)\n",
    "    vectorstore = create_vectorstore_with_metadata(documents)\n",
    "    return [vectorstore, documents]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore_ml, documents_ml = prepare_vectorstore_from_pdfs_with_ml(pdf_files, chunk_size=2000, overlap=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question_with_history_v3(question, vectorstore, conversation_history):\n",
    "    from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "    qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "        llm=llm,\n",
    "        retriever=vectorstore.as_retriever(),\n",
    "        return_source_documents=True  # Garante que as fontes sejam retornadas\n",
    "    )\n",
    "\n",
    "    result = qa_chain({\"question\": question, \"chat_history\": conversation_history})\n",
    "\n",
    "    conversation_history.append((question, result[\"answer\"]))\n",
    "\n",
    "    metadata_list = []\n",
    "    for doc in result[\"source_documents\"]:\n",
    "        metadata = doc.metadata\n",
    "        metadata_list.append({\n",
    "\n",
    "            \"topico_1\": metadata.get(\"topico_1\"),\n",
    "            \"topico_2\": metadata.get(\"topico_2\"),\n",
    "            \"content\": doc.page_content\n",
    "        })\n",
    "\n",
    "    return {\n",
    "        \"response\": result[\"answer\"],\n",
    "        \"context_used\": metadata_list,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resposta Gerada:\n",
      "As perdas e danos são conceitos importantes na teoria jurídica, especialmente no direito civil. Aqui está uma explicação detalhada sobre o que são perdas e danos:\n",
      "\n",
      "**O que são perdas?**\n",
      "\n",
      "As perdas são os prejuízos ou consequências negativas que alguém sofre como resultado de um ato ou ação de outra pessoa. São consideradas como parte do dano moral e material que a vítima sofreu.\n",
      "\n",
      "**Tipos de perdas**\n",
      "\n",
      "Existem dois tipos principais de perdas:\n",
      "\n",
      "1. **Perdas materiais**: são os prejuízos financeiros ou econômicos que a vítima sofreu, como danos à propriedade, perda de renda, etc.\n",
      "2. **Perdas morais**: são os prejuízos emocionais e psicológicos que a vítima sofreu, como dor, angústia, estresse, etc.\n",
      "\n",
      "**O que são danos?**\n",
      "\n",
      "Os danos são as consequências negativas que alguém sofre como resultado de um ato ou ação de outra pessoa. São consideradas como parte do dano moral e material que a vítima sofreu.\n",
      "\n",
      "**Tipos de danos**\n",
      "\n",
      "Existem dois tipos principais de danos:\n",
      "\n",
      "1. **Dano material**: é o prejuízo econômico ou financeiro que a vítima sofreu, como danos à propriedade, perda de renda, etc.\n",
      "2. **Dano moral**: é o prejuízo emocional e psicológico que a vítima sofreu, como dor, angústia, estresse, etc.\n",
      "\n",
      "**Exemplos**\n",
      "\n",
      "* Se alguém é atropelado por um carro e sofre danos físicos e morais, as perdas e danos incluem:\n",
      " + Perda de renda devido à incapacidade de trabalhar\n",
      " + Danos à propriedade do veículo\n",
      " + Dor e angústia emocional\n",
      "* Se alguém é vítima de um acidente de trabalho e sofre danos físicos e morais, as perdas e danos incluem:\n",
      " + Perda de renda devido à incapacidade de trabalhar\n",
      " + Danos à saúde e bem-estar\n",
      " + Dor e angústia emocional\n",
      "\n",
      "**Conclusão**\n",
      "\n",
      "As perdas e danos são conceitos importantes na teoria jurídica, especialmente no direito civil. São consideradas como parte do dano moral e material que a vítima sofreu. É fundamental entender os tipos de perdas e danos para poder avaliar as consequências negativas que alguém sofreu como resultado de um ato ou ação de outra pessoa.\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Tópico 1: art que se em mora\n",
      "Tópico 2: não segurança 411 incluem fixado\n",
      "Conteúdo:\n",
      "CAPÍTuLo iii\n",
      "Das Perdas e Danos\n",
      "Art. 402. Salvo as exceções expressamente previstas em lei, as perdas e danos\n",
      "devidas ao credor abrangem, além do que ele efetivamente perdeu, o que razoavel-\n",
      "mente deixou de lucrar.\n",
      "Art. 403. Ainda que a inexecução resulte de dolo do devedor, as perdas e danos só\n",
      "incluem os prejuízos efetivos e os lucros cessantes por efeito dela direto e imediato,\n",
      "sem prejuízo do disposto na lei processual.\n",
      "Art. 404. As perdas e danos, nas obrigações de pagamento em dinheiro, serão pagas\n",
      "com atualização monetária segundo índices oficiais regularmente estabelecidos, abran-\n",
      "gendo juros, custas e honorários de advogado, sem prejuízo da pena convencional.\n",
      "Parágrafo único. Provado que os juros da mora não cobrem o prejuízo, e não ha-\n",
      "vendo pena convencional, pode o juiz conceder ao credor indenização suplementar.\n",
      "Art. 405. Contam-se os juros de mora desde a citação inicial.\n",
      "CAPÍTuLo iv\n",
      "Dos Juros Legais\n",
      "Art. 406. Quando os juros moratórios não forem convencionados, ou o forem sem\n",
      "taxa estipulada, ou quando provierem de determinação da lei, serão fixados segundo a\n",
      "taxa que estiver em vigor para a mora do pagamento de impostos devidos à Fazenda\n",
      "Nacional.\n",
      "Art. 407. Ainda que se não alegue prejuízo, é obrigado o devedor aos juros da mora\n",
      "que se contarão assim às dívidas em dinheiro, como às prestações de outra natureza,\n",
      "uma vez que lhes esteja fixado o valor pecuniário por sentença judicial, arbitramento,\n",
      "ou acordo entre as partes.\n",
      "CAPÍTuLo v\n",
      "Da Cláusula Penal\n",
      "Art. 408. Incorre de pleno direito o devedor na cláusula penal, desde que, culpo-\n",
      "samente, deixe de cumprir a obrigação ou se constitua em mora.\n",
      "Art. 409. A cláusula penal estipulada conjuntamente com a obrigação, ou em ato\n",
      "posterior, pode referir-se à inexecução completa da obrigação, à de alguma cláusula\n",
      "especial ou simplesmente à mora.\n",
      "Art. 410. Quando se estipular a cláusula penal para o caso de total inadimplemento\n",
      "da obrigação, esta converter-se-á em alternativa a benefício do credor.\n",
      "Art. 411. Quando se estipular a cláusula penal para o caso de mora, ou em segurança\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Tópico 1: art que se em mora\n",
      "Tópico 2: forem com credor dinheiro estipular\n",
      "Conteúdo:\n",
      "CAPÍTuLo iii\n",
      "Das Perdas e Danos\n",
      "Art. 402. Salvo as exceções expressamente previstas em lei, as perdas e danos\n",
      "devidas ao credor abrangem, além do que ele efetivamente perdeu, o que razoavel-\n",
      "mente deixou de lucrar.\n",
      "Art. 403. Ainda que a inexecução resulte de dolo do devedor, as perdas e danos só\n",
      "incluem os prejuízos efetivos e os lucros cessantes por efeito dela direto e imediato,\n",
      "sem prejuízo do disposto na lei processual.\n",
      "Art. 404. As perdas e danos, nas obrigações de pagamento em dinheiro, serão pagas\n",
      "com atualização monetária segundo índices oficiais regularmente estabelecidos, abran-\n",
      "gendo juros, custas e honorários de advogado, sem prejuízo da pena convencional.\n",
      "Parágrafo único. Provado que os juros da mora não cobrem o prejuízo, e não ha-\n",
      "vendo pena convencional, pode o juiz conceder ao credor indenização suplementar.\n",
      "Art. 405. Contam-se os juros de mora desde a citação inicial.\n",
      "CAPÍTuLo iv\n",
      "Dos Juros Legais\n",
      "Art. 406. Quando os juros moratórios não forem convencionados, ou o forem sem\n",
      "taxa estipulada, ou quando provierem de determinação da lei, serão fixados segundo a\n",
      "taxa que estiver em vigor para a mora do pagamento de impostos devidos à Fazenda\n",
      "Nacional.\n",
      "Art. 407. Ainda que se não alegue prejuízo, é obrigado o devedor aos juros da mora\n",
      "que se contarão assim às dívidas em dinheiro, como às prestações de outra natureza,\n",
      "uma vez que lhes esteja fixado o valor pecuniário por sentença judicial, arbitramento,\n",
      "ou acordo entre as partes.\n",
      "CAPÍTuLo v\n",
      "Da Cláusula Penal\n",
      "Art. 408. Incorre de pleno direito o devedor na cláusula penal, desde que, culpo-\n",
      "samente, deixe de cumprir a obrigação ou se constitua em mora.\n",
      "Art. 409. A cláusula penal estipulada conjuntamente com a obrigação, ou em ato\n",
      "posterior, pode referir-se à inexecução completa da obrigação, à de alguma cláusula\n",
      "especial ou simplesmente à mora.\n",
      "Art. 410. Quando se estipular a cláusula penal para o caso de total inadimplemento\n",
      "da obrigação, esta converter-se-á em alternativa a benefício do credor.\n",
      "Art. 411. Quando se estipular a cláusula penal para o caso de mora, ou em segurança\n",
      "especial de outra cláusula determinada, terá o credor o arbítrio de exigir a satisfação\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Tópico 1: art que da se em\n",
      "Tópico 2: juros convencional dela prestações desempenho\n",
      "Conteúdo:\n",
      "CAPÍTuLo iii\n",
      "Das Perdas e Danos\n",
      "Art. 402. Salvo as exceções expressamente previstas em lei, as perdas e danos\n",
      "devidas ao credor abrangem, além do que ele efetivamente perdeu, o que razoavel-\n",
      "mente deixou de lucrar.\n",
      "Art. 403. Ainda que a inexecução resulte de dolo do devedor, as perdas e danos só\n",
      "incluem os prejuízos efetivos e os lucros cessantes por efeito dela direto e imediato,\n",
      "sem prejuízo do disposto na lei processual.\n",
      "Art. 404. As perdas e danos, nas obrigações de pagamento em dinheiro, serão pagas\n",
      "com atualização monetária segundo índices oficiais regularmente estabelecidos, abran-\n",
      "gendo juros, custas e honorários de advogado, sem prejuízo da pena convencional.\n",
      "Parágrafo único. Provado que os juros da mora não cobrem o prejuízo, e não ha-\n",
      "vendo pena convencional, pode o juiz conceder ao credor indenização suplementar.\n",
      "Art. 405. Contam-se os juros de mora desde a citação inicial.\n",
      "CAPÍTuLo iv\n",
      "Dos Juros Legais\n",
      "Art. 406. Quando os juros moratórios não forem convencionados, ou o forem sem\n",
      "taxa estipulada, ou quando provierem de determinação da lei, serão fixados segundo a\n",
      "taxa que estiver em vigor para a mora do pagamento de impostos devidos à Fazenda\n",
      "Nacional.\n",
      "Art. 407. Ainda que se não alegue prejuízo, é obrigado o devedor aos juros da mora\n",
      "que se contarão assim às dívidas em dinheiro, como às prestações de outra natureza,\n",
      "uma vez que lhes esteja fixado o valor pecuniário por sentença judicial, arbitramento,\n",
      "ou acordo entre as partes.\n",
      "CAPÍTuLo v\n",
      "Da Cláusula Penal\n",
      "Art. 408. Incorre de pleno direito o devedor na cláusula penal, desde que, culpo-\n",
      "samente, deixe de cumprir a obrigação ou se constitua em mora.\n",
      "Art. 409. A cláusula penal estipulada conjuntamente com a obrigação, ou em ato\n",
      "posterior, pode referir-se à inexecução completa da obrigação, à de alguma cláusula\n",
      "especial ou simplesmente à mora.\n",
      "Art. 410. Quando se estipular a cláusula penal para o caso de total inadimplemento\n",
      "da obrigação, esta converter-se-á em alternativa a benefício do credor.\n",
      "Art. 411. Quando se estipular a cláusula penal para o caso de mora, ou em segurança\n",
      "especial de outra cláusula determinada, terá o credor o arbítrio de exigir a satisfação\n",
      "da pena cominada, juntamente com o desempenho da obrigação principal.\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Tópico 1: art da que em se\n",
      "Tópico 2: ato entre com cumprir incluem\n",
      "Conteúdo:\n",
      "CAPÍTuLo iii\n",
      "Das Perdas e Danos\n",
      "Art. 402. Salvo as exceções expressamente previstas em lei, as perdas e danos\n",
      "devidas ao credor abrangem, além do que ele efetivamente perdeu, o que razoavel-\n",
      "mente deixou de lucrar.\n",
      "Art. 403. Ainda que a inexecução resulte de dolo do devedor, as perdas e danos só\n",
      "incluem os prejuízos efetivos e os lucros cessantes por efeito dela direto e imediato,\n",
      "sem prejuízo do disposto na lei processual.\n",
      "Art. 404. As perdas e danos, nas obrigações de pagamento em dinheiro, serão pagas\n",
      "com atualização monetária segundo índices oficiais regularmente estabelecidos, abran-\n",
      "gendo juros, custas e honorários de advogado, sem prejuízo da pena convencional.\n",
      "Parágrafo único. Provado que os juros da mora não cobrem o prejuízo, e não ha-\n",
      "vendo pena convencional, pode o juiz conceder ao credor indenização suplementar.\n",
      "Art. 405. Contam-se os juros de mora desde a citação inicial.\n",
      "CAPÍTuLo iv\n",
      "Dos Juros Legais\n",
      "Art. 406. Quando os juros moratórios não forem convencionados, ou o forem sem\n",
      "taxa estipulada, ou quando provierem de determinação da lei, serão fixados segundo a\n",
      "taxa que estiver em vigor para a mora do pagamento de impostos devidos à Fazenda\n",
      "Nacional.\n",
      "Art. 407. Ainda que se não alegue prejuízo, é obrigado o devedor aos juros da mora\n",
      "que se contarão assim às dívidas em dinheiro, como às prestações de outra natureza,\n",
      "uma vez que lhes esteja fixado o valor pecuniário por sentença judicial, arbitramento,\n",
      "ou acordo entre as partes.\n",
      "CAPÍTuLo v\n",
      "Da Cláusula Penal\n",
      "Art. 408. Incorre de pleno direito o devedor na cláusula penal, desde que, culpo-\n",
      "samente, deixe de cumprir a obrigação ou se constitua em mora.\n",
      "Art. 409. A cláusula penal estipulada conjuntamente com a obrigação, ou em ato\n",
      "posterior, pode referir-se à inexecução completa da obrigação, à de alguma cláusula\n",
      "especial ou simplesmente à mora.\n",
      "Art. 410. Quando se estipular a cláusula penal para o caso de total inadimplemento\n",
      "da obrigação, esta converter-se-á em alternativa a benefício do credor.\n",
      "Art. 411. Quando se estipular a cláusula penal para o caso de mora, ou em segurança\n",
      "especial de outra cláusula determinada, terá o credor o arbítrio de exigir a satisfação\n",
      "da pena cominada, juntamente com o desempenho da obrigação principal.\n",
      "190 Código Civil Brasileiro\n",
      "-------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Exemplo de uso\n",
    "conversation_history = []\n",
    "response1 = ask_question_with_history_v3(\n",
    "    \"Perdas e danos\",\n",
    "    vectorstore_ml,\n",
    "    conversation_history\n",
    ")\n",
    "\n",
    "# Exibir resposta e contexto\n",
    "print(\"\\nResposta Gerada:\")\n",
    "print(response1[\"response\"])\n",
    "print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "for context in response1[\"context_used\"]:\n",
    "    print(f\"Tópico 1: {context.get('topico_1', 'Não encontrado')}\")\n",
    "    print(f\"Tópico 2: {context.get('topico_2', 'Não encontrado')}\")\n",
    "    print(\"Conteúdo:\")\n",
    "    print(context.get(\"content\", \"Conteúdo não encontrado\"))\n",
    "    print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusão\n",
    "\n",
    "O uso da técnica de Machine Learning (ML) não resultou em uma melhoria significativa no desempenho. Além disso, os metadados gerados não se mostraram suficientemente interessantes para alcançar os objetivos do projeto.\n",
    "\n",
    "Uma abordagem alternativa foi tentar utilizar Large Language Models (LLMs) para a criação de metadados. No entanto, o custo computacional dessa solução foi inviável devido às limitações de hardware.\n",
    "\n",
    "\n",
    "\n",
    "Em resumo, nenhuma das abordagens exploradas conseguiu atender às expectativas iniciais, seja por limitações de hardware ou pela falta de qualidade nos resultados gerados.\n",
    "\n",
    "\n",
    "Embora as abordagens anteriores não tenham gerado resultados satisfatórios, a técnica de divisão em chunks, combinada com alguns metadados extraídos utilizando expressões regulares (regex), apresentou um desempenho bom o suficiente. \n",
    "\n",
    "Além disso, a utilização do histórico como contexto adicional contribuiu significativamente para melhorar os resultados, possibilitando uma abordagem mais eficiente e alinhada às limitações de hardware disponíveis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
